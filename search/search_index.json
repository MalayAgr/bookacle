{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"bookacle","text":"<p>Answer queries on complex PDF queries using RAPTOR-based RAG.</p> <p>For more details on RAPTOR, refer to the paper: https://arxiv.org/abs/2401.18059.</p>"},{"location":"#raptor-overview","title":"RAPTOR Overview","text":""},{"location":"#features","title":"Features","text":"<ul> <li>Everything is a Protocol, allowing for convenient extensibility.</li> <li>Use custom embedding models, summarization models, question-answering models and many more easily - just implement the protocol.</li> <li>Sensible default implementations for all of the above:<ul> <li>SentenceTransformerEmbeddingModel - Use any embedding model from the <code>sentence-transformers</code> library.</li> <li>HuggingFaceLLMSummarizationModel - Use an LLM from HuggingFace for summarization.</li> <li>OllamaQAModel - Use an LLM via Ollama for question-answering.</li> </ul> </li> </ul>"},{"location":"license/","title":"License","text":"<pre><code>MIT License\n\nCopyright (c) 2024 Malay Agarwal\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n\nIN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n</code></pre>"},{"location":"reference/","title":"bookacle","text":""},{"location":"reference/#bookacle","title":"bookacle","text":""},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li> bookacle<ul> <li> chat</li> <li> cli</li> <li> conf<ul> <li> config</li> </ul> </li> <li> document</li> <li> loaders</li> <li> models<ul> <li> embedding</li> <li> message</li> <li> qa</li> <li> summarization</li> </ul> </li> <li> splitters</li> <li> tokenizer</li> <li> tree<ul> <li> builder</li> <li> clustering</li> <li> config</li> <li> retriever</li> <li> structures</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/chat/","title":"bookacle.chat","text":""},{"location":"reference/chat/#bookacle.chat","title":"chat","text":"<p>Chat module for conversing with a RAPTOR RAG-based LLM in the terminal.</p>"},{"location":"reference/chat/#bookacle.chat.Chat","title":"Chat","text":"<pre><code>Chat(\n    retriever: RetrieverLike,\n    qa_model: QAModelLike,\n    console: Console,\n    history_file: str = \".bookacle-chat-history.txt\",\n    user_avatar: str = \"\ud83d\udc64\",\n)\n</code></pre> <p>A terminal-based chat interface for interacting with a RAPTOR RAG-based LLM.</p> <p>Attributes:</p> <ul> <li> <code>retriever</code>               (<code>RetrieverLike</code>)           \u2013            <p>Retriever to use for retrieving relevant context.</p> </li> <li> <code>qa_model</code>               (<code>QAModelLike</code>)           \u2013            <p>QA model to use for answering questions.</p> </li> <li> <code>console</code>               (<code>Console</code>)           \u2013            <p>Rich Console to use for displaying messages.</p> </li> <li> <code>history_file</code>               (<code>str</code>)           \u2013            <p>File to store chat history.</p> </li> <li> <code>user_avatar</code>               (<code>str</code>)           \u2013            <p>Avatar to use for the user in the chat UI.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>retriever</code>               (<code>RetrieverLike</code>)           \u2013            <p>Retriever to use for retrieving relevant context.</p> </li> <li> <code>qa_model</code>               (<code>QAModelLike</code>)           \u2013            <p>QA model to use for answering questions.</p> </li> <li> <code>console</code>               (<code>Console</code>)           \u2013            <p>Rich Console to use for displaying messages.</p> </li> <li> <code>history_file</code>               (<code>str</code>, default:                   <code>'.bookacle-chat-history.txt'</code> )           \u2013            <p>File to store chat history. The file is created in the home directory.</p> </li> <li> <code>user_avatar</code>               (<code>str</code>, default:                   <code>'\ud83d\udc64'</code> )           \u2013            <p>Avatar to use for the user in the chat UI.</p> </li> </ul>"},{"location":"reference/chat/#bookacle.chat.Chat.display_ai_msg_stream","title":"display_ai_msg_stream","text":"<pre><code>display_ai_msg_stream(messages: Iterator[Message]) -&gt; str\n</code></pre> <p>Display an AI message stream in the chat UI.</p> <p>Parameters:</p> <ul> <li> <code>messages</code>               (<code>Iterator[Message]</code>)           \u2013            <p>Stream of AI messages to display.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>The complete message as a string.</p> </li> </ul>"},{"location":"reference/chat/#bookacle.chat.Chat.invoke_qa_model","title":"invoke_qa_model","text":"<pre><code>invoke_qa_model(\n    tree: Tree,\n    question: str,\n    history: list[Message] | None = None,\n    stream: bool = True,\n    *args,\n    **kwargs\n) -&gt; Message\n</code></pre> <p>Invoke the QA model to answer a question.</p> <p>Parameters:</p> <ul> <li> <code>tree</code>               (<code>Tree</code>)           \u2013            <p>RAPTOR tree that should be used for RAG.</p> </li> <li> <code>question</code>               (<code>str</code>)           \u2013            <p>The question to answer.</p> </li> <li> <code>history</code>               (<code>list[Message] | None</code>, default:                   <code>None</code> )           \u2013            <p>Chat history.</p> </li> <li> <code>stream</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to stream the AI response.</p> </li> <li> <code>**args</code>               (<code>tuple[Any]</code>, default:                   <code>()</code> )           \u2013            <p>Additional positional arguments to pass to the retriever.</p> </li> <li> <code>**kwargs</code>               (<code>dict[str, Any]</code>, default:                   <code>{}</code> )           \u2013            <p>Additional keyword arguments to pass to the retriever.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Message</code>           \u2013            <p>The response from the QA model.</p> </li> </ul>"},{"location":"reference/chat/#bookacle.chat.Chat.run","title":"run","text":"<pre><code>run(\n    tree: Tree,\n    initial_chat_message: str = \"\",\n    system_prompt: str = \"\",\n    stream: bool = True,\n    *args,\n    **kwargs\n) -&gt; None\n</code></pre> <p>Run the chat interface.</p> <p>Parameters:</p> <ul> <li> <code>tree</code>               (<code>Tree</code>)           \u2013            <p>RAPTOR tree that should be used for RAG.</p> </li> <li> <code>initial_chat_message</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>Initial message to display in the chat.</p> </li> <li> <code>system_prompt</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>System prompt that should be used for the QA model.</p> </li> <li> <code>stream</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to stream the AI response.</p> </li> <li> <code>*args</code>               (<code>tuple[Any]</code>, default:                   <code>()</code> )           \u2013            <p>Additional positional arguments to pass to the retriever.</p> </li> <li> <code>**kwargs</code>               (<code>dict[str, Any]</code>, default:                   <code>{}</code> )           \u2013            <p>Additional keyword arguments to pass to the retriever.</p> </li> </ul>"},{"location":"reference/cli/","title":"bookacle.cli","text":""},{"location":"reference/cli/#bookacle.cli","title":"cli","text":""},{"location":"reference/document/","title":"bookacle.document","text":""},{"location":"reference/document/#bookacle.document","title":"document","text":"<p>This module defines the document structure used throughout the package.</p>"},{"location":"reference/document/#bookacle.document.Document","title":"Document","text":"<p>               Bases: <code>TypedDict</code></p> <p>A TypedDict that represents a page in a PDF file.</p> <p>Attributes:</p> <ul> <li> <code>page_content</code>               (<code>str</code>)           \u2013            <p>The text content of the page.</p> </li> <li> <code>metadata</code>               (<code>NotRequired[dict[str, Any]]</code>)           \u2013            <p>Additional metadata about the page.</p> </li> </ul>"},{"location":"reference/loaders/","title":"bookacle.loaders","text":""},{"location":"reference/loaders/#bookacle.loaders","title":"loaders","text":"<p>This module defines functions for loading PDF documents and some utilities to manage loaders.</p>"},{"location":"reference/loaders/#bookacle.loaders.LOADER_MANAGER","title":"LOADER_MANAGER  <code>module-attribute</code>","text":"<pre><code>LOADER_MANAGER = LoaderManager()\n</code></pre> <p>Default loader manager.</p>"},{"location":"reference/loaders/#bookacle.loaders.LoaderLike","title":"LoaderLike","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol that all document loaders should follow.</p>"},{"location":"reference/loaders/#bookacle.loaders.LoaderLike.__call__","title":"__call__","text":"<pre><code>__call__(\n    file_path: str,\n    start_page: int = 0,\n    end_page: int | None = None,\n) -&gt; list[Document]\n</code></pre> <p>Load a PDF document.</p> <p>Parameters:</p> <ul> <li> <code>file_path</code>               (<code>str</code>)           \u2013            <p>The path to the PDF file.</p> </li> <li> <code>start_page</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The starting (0-based) page number in the PDF to begin reading from.</p> </li> <li> <code>end_page</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The ending (0-based) page number to stop reading at (non-inclusive).       When <code>None</code>, all pages in the PDF are read.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[Document]</code>           \u2013            <p>Pages in the file.</p> </li> </ul>"},{"location":"reference/loaders/#bookacle.loaders.LoaderManager","title":"LoaderManager","text":"<p>               Bases: <code>UserDict[str, LoaderLike]</code></p> <p>Manager to maintain registry of all document loaders.</p> <p>It behaves like a dictionary, where each document loader is registered to a name.</p> <p>Examples:</p> <pre><code>from bookacle.loaders import LoaderManager, register_loader\nfrom langchain_core.documents import Document\n\nmanager = LoaderManager()\n\n@register_loader(name=\"custom_loader\", manager=manager)\ndef doc_loader(file_path: str, start_page: int = 0, end_page: int | None = None) -&gt; list[Document]:\n    ...\n\nprint(manager[\"custom_loader\"] is doc_loader)\n</code></pre> <pre><code>True\n</code></pre>"},{"location":"reference/loaders/#bookacle.loaders.LoaderManager.enum","title":"enum  <code>property</code>","text":"<pre><code>enum: Enum\n</code></pre> <p>Obtain the names of the document loaders as an Enum.</p> <p>Useful in the CLI for <code>--help</code>.</p>"},{"location":"reference/loaders/#bookacle.loaders.pymupdf4llm_loader","title":"pymupdf4llm_loader","text":"<pre><code>pymupdf4llm_loader(\n    file_path: str,\n    start_page: int = 0,\n    end_page: int | None = None,\n) -&gt; list[Document]\n</code></pre> <p>Document loader which uses <code>pymupdf4llm</code> to load the PDF as Markdown.</p> <p>Can be accessed using the name <code>'pymupdf4llm'</code> via the default loader manager.</p> <p>It implements the LoaderLike protocol.</p>"},{"location":"reference/loaders/#bookacle.loaders.pymupdf_loader","title":"pymupdf_loader","text":"<pre><code>pymupdf_loader(\n    file_path: str,\n    start_page: int = 0,\n    end_page: int | None = None,\n) -&gt; list[Document]\n</code></pre> <p>Document loader which uses <code>pymupdf</code> to load the PDF as text.</p> <p>Can be accessed using the name <code>'pymupdf'</code> via the default loader manager.</p> <p>It implements the LoaderLike protocol.</p>"},{"location":"reference/loaders/#bookacle.loaders.register_loader","title":"register_loader","text":"<pre><code>register_loader(\n    name: str, manager: LoaderManager | None = None\n) -&gt; Callable[[LoaderLike], LoaderLike]\n</code></pre> <p>A decorator that registers a loader function with the loader manager.</p> <p>Parameters:</p> <ul> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>The name to map the loader function to.</p> </li> <li> <code>manager</code>               (<code>LoaderManager | None</code>, default:                   <code>None</code> )           \u2013            <p>The manager to register the function with.      If <code>None</code>, <code>LOADER_MANAGER</code> is used.</p> </li> </ul>"},{"location":"reference/splitters/","title":"bookacle.splitters","text":""},{"location":"reference/splitters/#bookacle.splitters","title":"splitters","text":"<p>This module implements document splitters for document chunking.</p>"},{"location":"reference/splitters/#bookacle.splitters.DocumentSplitterLike","title":"DocumentSplitterLike","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol that defines the methods that a document splitter should implement.</p>"},{"location":"reference/splitters/#bookacle.splitters.DocumentSplitterLike.__call__","title":"__call__","text":"<pre><code>__call__(\n    documents: list[Document],\n    chunk_size: int = 100,\n    chunk_overlap: int = 0,\n) -&gt; list[Document]\n</code></pre> <p>Split a list of documents into smaller chunks.</p> <p>Parameters:</p> <ul> <li> <code>documents</code>               (<code>list[Document]</code>)           \u2013            <p>The list of documents to be split.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>The size of each chunk.</p> </li> <li> <code>chunk_overlap</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The overlap between consecutive chunks.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[Document]</code>           \u2013            <p>The list of documents after splitting into chunks.</p> </li> </ul>"},{"location":"reference/splitters/#bookacle.splitters.HuggingFaceMarkdownSplitter","title":"HuggingFaceMarkdownSplitter","text":"<pre><code>HuggingFaceMarkdownSplitter(\n    tokenizer: PreTrainedTokenizerBase,\n)\n</code></pre> <p>Markdown-based document splitter which uses a HuggingFace tokenizer to calculate length of chunks when splitting.</p> <p>It uses Langchain\u2019s MarkdownTextSplitter and expects the list of documents to be in Markdown.</p> <p>It implements the DocumentSplitterLike protocol.</p> <p>Attributes:</p> <ul> <li> <code>tokenizer</code>           \u2013            <p>The HuggingFace tokenizer to use for calculating length.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>tokenizer</code>               (<code>PreTrainedTokenizerBase</code>)           \u2013            <p>The HuggingFace tokenizer to use to calculate length.</p> </li> </ul>"},{"location":"reference/splitters/#bookacle.splitters.HuggingFaceTextSplitter","title":"HuggingFaceTextSplitter","text":"<pre><code>HuggingFaceTextSplitter(\n    tokenizer: PreTrainedTokenizerBase,\n    separators: list[str] | None = None,\n)\n</code></pre> <p>Text-based document splitter which uses a HuggingFace tokenizer to calculate length when splitting.</p> <p>It uses Langchain\u2019s RecursiveCharacterTextSplitter and expects the list of documents to be in plain text.</p> <p>It implements the DocumentSplitterLike protocol.</p> <p>Attributes:</p> <ul> <li> <code>tokenizer</code>           \u2013            <p>The HuggingFace tokenizer to use for calculating length.</p> </li> <li> <code>separators</code>           \u2013            <p>The list of separators to use for splitting the document.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>tokenizer</code>               (<code>PreTrainedTokenizerBase</code>)           \u2013            <p>The HuggingFace tokenizer to use for calculating length.</p> </li> <li> <code>separators</code>               (<code>list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>The list of separators to use.         When <code>None</code>, the default separators are used: <code>[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\"]</code>.</p> </li> </ul>"},{"location":"reference/splitters/#bookacle.splitters.RaptorSplitter","title":"RaptorSplitter","text":"<pre><code>RaptorSplitter(\n    tokenizer: TokenizerLike,\n    *,\n    separators: list[str] | None = None\n)\n</code></pre> <p>Document splitter which implements the chunking technique as defined in the RAPTOR paper.</p> <p>It expects a tokenizer which implements the TokenizerLike protocol to calculate the length of chunks.</p> <p>For more details, see: https://github.com/parthsarthi03/raptor/blob/7da1d48a7e1d7dec61a63c9d9aae84e2dfaa5767/raptor/utils.py#L22.</p> <p>It implements the DocumentSplitterLike protocol.</p> <p>Attributes:</p> <ul> <li> <code>tokenizer</code>           \u2013            <p>Tokenizer to use for calculating chunk lengths.</p> </li> <li> <code>separators</code>           \u2013            <p>The list of separators to use for splitting the document.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>tokenizer</code>               (<code>TokenizerLike</code>)           \u2013            <p>Tokenizer to use for calculating chunk lengths.</p> </li> <li> <code>separators</code>               (<code>list[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>The list of separators to use.         When <code>None</code>, the default separators are used: <code>[\".\", \"!\", \"?\", \"\\n\"]</code>.</p> </li> </ul>"},{"location":"reference/splitters/#bookacle.splitters.RaptorSplitter.split_single_document","title":"split_single_document","text":"<pre><code>split_single_document(\n    document: Document, chunk_size: int, chunk_overlap: int\n) -&gt; list[Document]\n</code></pre> <p>Split a single document into chunks.</p> <p>Parameters:</p> <ul> <li> <code>document</code>               (<code>Document</code>)           \u2013            <p>Document to split into chunks.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>Maximum size of each chunk.</p> </li> <li> <code>chunk_overlap</code>               (<code>int</code>)           \u2013            <p>Overlap between each chunk.</p> </li> </ul>"},{"location":"reference/tokenizer/","title":"bookacle.tokenizer","text":""},{"location":"reference/tokenizer/#bookacle.tokenizer","title":"tokenizer","text":""},{"location":"reference/tokenizer/#bookacle.tokenizer.TokenizerLike","title":"TokenizerLike","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol that all tokenizers should follow.</p>"},{"location":"reference/tokenizer/#bookacle.tokenizer.TokenizerLike.encode","title":"encode","text":"<pre><code>encode(*args, **kwargs) -&gt; list[int]\n</code></pre> <p>Tokenize the input text into a list of integers.</p> <p>Returns:</p> <ul> <li> <code>list[int]</code>           \u2013            <p>Tokenized input.</p> </li> </ul>"},{"location":"reference/conf/","title":"bookacle.conf","text":""},{"location":"reference/conf/#bookacle.conf","title":"conf","text":""},{"location":"reference/conf/config/","title":"bookacle.conf.config","text":""},{"location":"reference/conf/config/#bookacle.conf.config","title":"config","text":"<p>This module manages loading and validating configuration settings for the application from TOML files.</p> <p>It also provides utility functions for importing classes and instantiating objects based on their dotted paths.</p>"},{"location":"reference/conf/config/#bookacle.conf.config.settings","title":"settings  <code>module-attribute</code>","text":"<pre><code>settings: LazySettings = Dynaconf(\n    envvar_prefix=\"BOOKACLE\",\n    root_path=ROOT_PATH,\n    settings_files=[\"settings.toml\", \"prompts.toml\"],\n)\n</code></pre> <p>Settings for the application.</p> <p>The following validators are registered on the settings object.</p> <pre><code>from dynaconf import Validator\n\n[\nValidator(\n    \"custom_loaders_dir\",\n    \"clustering_func\",\n    \"stream_output\",\n    \"embedding_model.model_class\",\n    \"embedding_model.model_arguments\",\n    \"summarization_model.model_class\",\n    \"summarization_model.model_arguments\",\n    \"document_splitter.splitter_class\",\n    \"document_splitter.splitter_arguments\",\n    \"retriever.retriever_class\",\n    \"retriever.retriever_arguments\",\n    \"clustering_backend.backend_class\",\n    \"clustering_backend.backend_arguments\",\n    \"qa_model.model_class\",\n    \"qa_model.model_arguments\",\n    must_exist=True,\n),\nValidator(\n    \"embedding_model\",\n    cast=lambda value: cast_class_path_to_instance(\n        value[\"model_class\"], value[\"model_arguments\"]\n    ),\n),\nValidator(\n    \"summarization_model\",\n    cast=lambda value: cast_class_path_to_instance(\n        class_path=value[\"model_class\"],\n        arguments=value[\"model_arguments\"],\n    ),\n),\nValidator(\"document_splitter\", cast=cast_document_splitter),\nValidator(\"retriever_config\", cast=cast_retriever_config),\nValidator(\n    \"retriever\",\n    cast=lambda value: cast_class_path_to_instance(\n        class_path=value[\"retriever_class\"],\n        arguments=value[\"retriever_arguments\"],\n    ),\n),\nValidator(\"clustering_func\", cast=import_attribute_from_module),\nValidator(\n    \"clustering_backend\",\n    cast=lambda value: cast_class_path_to_instance(\n        class_path=value[\"backend_class\"],\n        arguments=value[\"backend_arguments\"],\n    ),\n),\nValidator(\n    \"tree_builder_config\",\n    cast=lambda value: cast_class_path_to_instance(\n        class_path=value[\"config_class\"], arguments=value[\"config_arguments\"]\n    ),\n),\nValidator(\n    \"tree_builder\",\n    cast=lambda value: cast_class_path_to_instance(\n        class_path=value[\"builder_class\"],\n        arguments=value[\"builder_arguments\"],\n    ),\n),\nValidator(\n    \"qa_model\",\n    cast=lambda value: cast_class_path_to_instance(\n        class_path=value[\"model_class\"], arguments=value[\"model_arguments\"]\n    ),\n),\nValidator(\"chunk_size\", default=None),\nValidator(\"chunk_overlap\", default=None),\n]\n</code></pre> <p>Note that the validators are not applied automatically since there is overhead (for example, in casting the embedding models and summarization models).</p> <p>To apply the validators, call <code>settings.validators.validate()</code>.</p> <p>For more details, see the Dynaconf documentation on validators: https://www.dynaconf.com/validation/.</p> <p>The default settings are loaded from the <code>settings.toml</code> and <code>prompts.toml</code>.</p> <ul> <li><code>settings.toml</code> contains the main configuration settings.</li> <li><code>prompts.toml</code> contains the prompts for the user interface.</li> </ul> <p>The settings can be accessed as a dictionary or as attributes. For example:</p> <pre><code>from bookacle.conf import settings\n# Validate the settings\nsettings.validators.validate()\n# Access as attribute\nprint(f\"Default embedding model: {settings.EMBEDDING_MODEL}\")\n# Access as dictionary\nprint(f\"Default QA model: {settings['qa_model']}\")\n</code></pre> <pre><code>Default embedding model: SentenceTransformerEmbeddingModel(model_name='paraphrase-albert-small-v2', use_gpu=False)\nDefault QA model: OllamaQAModel(model_name='qwen2:0.5b')\n</code></pre> <p>For more details on managing settings, see Configuration.</p>"},{"location":"reference/conf/config/#bookacle.conf.config.cast_class_path_to_instance","title":"cast_class_path_to_instance","text":"<pre><code>cast_class_path_to_instance(\n    class_path: str, arguments: dict[str, Any]\n) -&gt; object\n</code></pre> <p>Instantiates a class by its dotted path and passes the provided arguments.</p> <p>Parameters:</p> <ul> <li> <code>class_path</code>               (<code>str</code>)           \u2013            <p>The full path to the class in the form \u2018module.submodule.ClassName\u2019.</p> </li> <li> <code>arguments</code>               (<code>dict[str, Any]</code>)           \u2013            <p>A dictionary of arguments to pass to the class constructor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>object</code>           \u2013            <p>An instance of the class.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ImportError</code>             \u2013            <p>If the module cannot be imported.</p> </li> <li> <code>AttributeError</code>             \u2013            <p>If the class does not exist in the module.</p> </li> </ul>"},{"location":"reference/conf/config/#bookacle.conf.config.cast_document_splitter","title":"cast_document_splitter","text":"<pre><code>cast_document_splitter(\n    value: dict[str, Any]\n) -&gt; DocumentSplitterLike\n</code></pre> <p>Casts a dictionary containing document splitter configuration into an instance of DocumentSplitterLike.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>dict[str, Any]</code>)           \u2013            <p>Dictionary containing the class path of the document splitter and its arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DocumentSplitterLike</code>           \u2013            <p>An instance of the document splitter class.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValidationError</code>             \u2013            <p>If the arguments has the <code>tokenizer_from</code> key              and it doesn\u2019t resolve to an implementation of              EmbeddingModelLike or              SummarizationModelLike.</p> </li> </ul>"},{"location":"reference/conf/config/#bookacle.conf.config.cast_retriever_config","title":"cast_retriever_config","text":"<pre><code>cast_retriever_config(\n    value: dict[str, Any]\n) -&gt; RetrieverLike\n</code></pre> <p>Casts a dictionary containing retriever configuration into an instance of RetrieverLike.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>dict[str, Any]</code>)           \u2013            <p>Dictionary with the class path of the retriever and its arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RetrieverLike</code>           \u2013            <p>An instance of the retriever class.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValidationError</code>             \u2013            <p>If the arguments has the <code>selection_mode</code> key              and it is not a member of the SelectionMode              Enum.</p> </li> </ul>"},{"location":"reference/conf/config/#bookacle.conf.config.import_attribute_from_module","title":"import_attribute_from_module","text":"<pre><code>import_attribute_from_module(dotted_path: str) -&gt; Type[Any]\n</code></pre> <p>Imports an attribute (class or function) from a dotted module path.</p> <p>Parameters:</p> <ul> <li> <code>dotted_path</code>               (<code>str</code>)           \u2013            <p>The full path to the attribute in the form of \u2018module.submodule.ClassName\u2019.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Type[Any]</code>           \u2013            <p>The imported attribute (e.g., a class or function).</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ImportError</code>             \u2013            <p>If the module cannot be imported.</p> </li> <li> <code>AttributeError</code>             \u2013            <p>If the attribute does not exist in the module.</p> </li> </ul>"},{"location":"reference/models/","title":"bookacle.models","text":""},{"location":"reference/models/#bookacle.models","title":"models","text":""},{"location":"reference/models/embedding/","title":"bookacle.models.embedding","text":""},{"location":"reference/models/embedding/#bookacle.models.embedding","title":"embedding","text":"<p>This module defines protocols and concrete implementations for embedding models used for text representation.</p>"},{"location":"reference/models/embedding/#bookacle.models.embedding.EmbeddingModelLike","title":"EmbeddingModelLike","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol that defines the methods and attributes that an embedding model should implement.</p>"},{"location":"reference/models/embedding/#bookacle.models.embedding.EmbeddingModelLike.model_max_length","title":"model_max_length  <code>property</code>","text":"<pre><code>model_max_length: int\n</code></pre> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>The maximum length of the input that the model can accept.</p> </li> </ul>"},{"location":"reference/models/embedding/#bookacle.models.embedding.EmbeddingModelLike.tokenizer","title":"tokenizer  <code>property</code>","text":"<pre><code>tokenizer: TokenizerLike\n</code></pre> <p>Returns:</p> <ul> <li> <code>TokenizerLike</code>           \u2013            <p>The tokenizer used by the model.</p> </li> </ul>"},{"location":"reference/models/embedding/#bookacle.models.embedding.EmbeddingModelLike.embed","title":"embed","text":"<pre><code>embed(\n    text: str | list[str],\n) -&gt; list[float] | list[list[float]]\n</code></pre> <p>Embed the input text or list of texts.</p> <p>Parameters:</p> <ul> <li> <code>text</code>               (<code>str | list[str]</code>)           \u2013            <p>The input text or list of input texts to embed.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[float] | list[list[float]]</code>           \u2013            <p>The embeddings of the input text or list of texts.</p> </li> </ul>"},{"location":"reference/models/embedding/#bookacle.models.embedding.SentenceTransformerEmbeddingModel","title":"SentenceTransformerEmbeddingModel","text":"<pre><code>SentenceTransformerEmbeddingModel(\n    model_name: str, *, use_gpu: bool = False\n)\n</code></pre> <p>An embedding model that uses the SentenceTransformer library.</p> <p>It implements the EmbeddingModelLike protocol.</p> <p>Attributes:</p> <ul> <li> <code>model_name</code>               (<code>str</code>)           \u2013            <p>The name of the model to use.</p> </li> <li> <code>use_gpu</code>               (<code>bool</code>)           \u2013            <p>Whether to use the GPU for inference.</p> </li> <li> <code>model</code>               (<code>SentenceTransformer</code>)           \u2013            <p>The SentenceTransformer model.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>model_name</code>               (<code>str</code>)           \u2013            <p>The name of the model to use.</p> </li> <li> <code>use_gpu</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to use the GPU for inference.</p> </li> </ul>"},{"location":"reference/models/embedding/#bookacle.models.embedding.SentenceTransformerEmbeddingModel.tokenizer","title":"tokenizer  <code>property</code>","text":"<pre><code>tokenizer: PreTrainedTokenizerBase\n</code></pre> <p>Returns:</p> <ul> <li> <code>PreTrainedTokenizerBase</code>           \u2013            <p>The tokenizer used by the underlying model.</p> </li> </ul>"},{"location":"reference/models/message/","title":"bookacle.models.message","text":""},{"location":"reference/models/message/#bookacle.models.message","title":"message","text":"<p>This module defines data structures for representing messages exchanged in a conversation with a language model (LLM).</p>"},{"location":"reference/models/message/#bookacle.models.message.Message","title":"Message","text":"<p>               Bases: <code>TypedDict</code></p> <p>A TypedDict that represents a message in a conversation with an LLM.</p> <p>Attributes:</p> <ul> <li> <code>role</code>               (<code>Literal['user', 'assistant', 'system', 'tool']</code>)           \u2013            <p>The role of the message sender.</p> </li> <li> <code>content</code>               (<code>str</code>)           \u2013            <p>The content of the message.</p> </li> </ul>"},{"location":"reference/models/qa/","title":"bookacle.models.qa","text":""},{"location":"reference/models/qa/#bookacle.models.qa","title":"qa","text":"<p>This module defines a protocol and an implementation for a Question-Answering (QA) model that processes questions and returns answers with or without streaming capabilities.</p>"},{"location":"reference/models/qa/#bookacle.models.qa.OllamaQAModel","title":"OllamaQAModel","text":"<pre><code>OllamaQAModel(model_name: str)\n</code></pre> <p>A QA model that uses the Ollama library.</p> <p>It implements the QAModelLike protocol.</p> <p>Attributes:</p> <ul> <li> <code>model_name</code>               (<code>str</code>)           \u2013            <p>The name of the model to use.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>model_name</code>               (<code>str</code>)           \u2013            <p>The name of the model to use.</p> </li> </ul>"},{"location":"reference/models/qa/#bookacle.models.qa.OllamaQAModel.answer","title":"answer","text":"<pre><code>answer(\n    question: str,\n    context: str,\n    history: list[Message] | None = None,\n    *args,\n    stream: bool = True,\n    **kwargs\n) -&gt; Message | Iterable[Message]\n</code></pre> <p>Answer a question given a context and chat history with or without streaming.</p> <p>The question and the context are combined into a single message for the QA model, using the following template:</p> <pre><code>CONTEXT:\n&lt;context&gt;\n\nQUERY: &lt;question&gt;\n</code></pre> <p>After combining the question and context, the message is appended to the history (if any) and sent to the QA model.</p> <p>A system prompt can be provided by adding it as the first message in the history.</p>"},{"location":"reference/models/qa/#bookacle.models.qa.QAModelLike","title":"QAModelLike","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol that defines the methods that a QA model should implement.</p>"},{"location":"reference/models/qa/#bookacle.models.qa.QAModelLike.answer","title":"answer","text":"<pre><code>answer(\n    question: str,\n    context: str,\n    history: list[Message] | None = None,\n    *args,\n    stream: bool = False,\n    **kwargs\n) -&gt; Message | Iterator[Message]\n</code></pre> <p>Answer a question given a context and chat history with or without streaming.</p> <p>Parameters:</p> <ul> <li> <code>question</code>               (<code>str</code>)           \u2013            <p>The question to answer.</p> </li> <li> <code>context</code>               (<code>str</code>)           \u2013            <p>The context for the question.</p> </li> <li> <code>history</code>               (<code>list[Message] | None</code>, default:                   <code>None</code> )           \u2013            <p>The chat history.</p> </li> <li> <code>stream</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to stream the AI response.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Message | Iterator[Message]</code>           \u2013            <p>A single message from the QA model or a stream of messages.</p> </li> </ul>"},{"location":"reference/models/summarization/","title":"bookacle.models.summarization","text":""},{"location":"reference/models/summarization/#bookacle.models.summarization","title":"summarization","text":"<p>This module defines protocols and concrete implementations for summarization models used for summarizing texts in intermediate RAPTOR tree layers.</p>"},{"location":"reference/models/summarization/#bookacle.models.summarization.HuggingFaceLLMSummarizationModel","title":"HuggingFaceLLMSummarizationModel","text":"<pre><code>HuggingFaceLLMSummarizationModel(\n    model_name: str,\n    summarization_length: int = 100,\n    *,\n    system_prompt: str = \"\",\n    use_gpu: bool = False\n)\n</code></pre> <p>A class that uses a Hugging Face LLM for summarization.</p> <p>It implements the SummarizationModelLike protocol.</p> <p>Attributes:</p> <ul> <li> <code>model_name</code>               (<code>str</code>)           \u2013            <p>The name of the Hugging Face LLM to use.</p> </li> <li> <code>summarization_length</code>               (<code>int</code>)           \u2013            <p>The maximum length of the summary.</p> </li> <li> <code>system_prompt</code>               (<code>str</code>)           \u2013            <p>The system prompt passed to the LLM for summarization.</p> </li> <li> <code>use_gpu</code>               (<code>bool</code>)           \u2013            <p>Whether to use the GPU for inference.</p> </li> <li> <code>model</code>               (<code>AutoModelForCausalLM</code>)           \u2013            <p>The Hugging Face LLM for summarization.</p> </li> <li> <code>pipeline</code>               (<code>Pipeline</code>)           \u2013            <p>The Hugging Face pipeline for summarization.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>model_name</code>               (<code>str</code>)           \u2013            <p>The name of the Hugging Face model to use.</p> </li> <li> <code>summarization_length</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>The maximum length of the summary.</p> </li> <li> <code>system_prompt</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The system prompt to pass to the LLM for summarization.</p> </li> <li> <code>use_gpu</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to use the GPU for inference.</p> </li> </ul>"},{"location":"reference/models/summarization/#bookacle.models.summarization.HuggingFaceLLMSummarizationModel.tokenizer","title":"tokenizer  <code>property</code>","text":"<pre><code>tokenizer: PreTrainedTokenizerBase\n</code></pre> <p>Returns:</p> <ul> <li> <code>PreTrainedTokenizerBase</code>           \u2013            <p>The Hugging Face tokenizer used by the underlying model.</p> </li> </ul>"},{"location":"reference/models/summarization/#bookacle.models.summarization.HuggingFaceLLMSummarizationModel.format_as_chat_message","title":"format_as_chat_message","text":"<pre><code>format_as_chat_message(\n    text: str | list[str],\n) -&gt; list[Message] | list[list[Message]]\n</code></pre> <p>Format the input text or list of texts as chat messages.</p> <p>A chat message is a dictionary with the keys \u2018role\u2019 and \u2018content\u2019.</p> If the input is a list of texts <ul> <li>If the system prompt is provided, a list of lists containing the system prompt and user message is returned.</li> <li>If the system prompt is not provided, a list of lists containing the user messages is returned.</li> </ul> If the input is a single text <ul> <li>If the system prompt is provided, a list containing the system prompt and user message is returned.</li> <li>If the system prompt is not provided, a list containing only the user message is returned.</li> </ul> <p>Parameters:</p> <ul> <li> <code>text</code>               (<code>str | list[str]</code>)           \u2013            <p>The input text or list of texts to format.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[Message] | list[list[Message]]</code>           \u2013            <p>The formatted chat messages.</p> </li> </ul> <p>Examples:</p> Single Text<pre><code>from bookacle.models.summarization import HuggingFaceLLMSummarizationModel\nmodel = HuggingFaceLLMSummarizationModel(model_name=\"Qwen/Qwen2-0.5B-Instruct\")\ntext = \"This is a test\"\nprint(model.format_as_chat_message(text))\n</code></pre> <pre><code>[{'role': 'user', 'content': 'Summarize the following in not more than 100 words:\\nThis is a test'}]\n</code></pre> Mutliple Texts<pre><code>from bookacle.models.summarization import HuggingFaceLLMSummarizationModel\nmodel = HuggingFaceLLMSummarizationModel(model_name=\"Qwen/Qwen2-0.5B-Instruct\")\ntext = [\"This is a test\", \"This is another test\"]\nprint(model.format_as_chat_message(text))\n</code></pre> <pre><code>[[{'role': 'user', 'content': 'Summarize the following in not more than 100 words:\\nThis is a test'}], [{'role': 'user', 'content': 'Summarize the following in not more than 100 words:\\nThis is another test'}]]\n</code></pre>"},{"location":"reference/models/summarization/#bookacle.models.summarization.HuggingFaceLLMSummarizationModel.summarize","title":"summarize","text":"<pre><code>summarize(text: str | list[str]) -&gt; str | list[str]\n</code></pre> <p>Summarize the input text or list of texts.</p> <p>The input is first formatted into chat messages using format_as_chat_message() and then passed to the underlying LLM for summarization.</p> <p>Each input text is passed to the LLM with the following format:</p> <pre><code>\"Summarize the following in not more than {summarization_length} words:\\n{text}\"\n</code></pre> <p>Parameters:</p> <ul> <li> <code>text</code>               (<code>str | list[str]</code>)           \u2013            <p>The input text or list of texts to summarize.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str | list[str]</code>           \u2013            <p>The summary of the input text or list of texts.</p> </li> </ul>"},{"location":"reference/models/summarization/#bookacle.models.summarization.HuggingFaceSummarizationModel","title":"HuggingFaceSummarizationModel","text":"<pre><code>HuggingFaceSummarizationModel(\n    model_name: str,\n    summarization_length: int = 100,\n    *,\n    use_gpu: bool = False\n)\n</code></pre> <p>A class that uses a Hugging Face model for summarization.</p> <p>It implements the SummarizationModelLike protocol.</p> <p>Attributes:</p> <ul> <li> <code>model_name</code>               (<code>str</code>)           \u2013            <p>The name of the Hugging Face model to use.</p> </li> <li> <code>summarization_length</code>               (<code>int</code>)           \u2013            <p>The maximum length of the summary.</p> </li> <li> <code>use_gpu</code>               (<code>bool</code>)           \u2013            <p>Whether to use the GPU for inference.</p> </li> <li> <code>model</code>               (<code>AutoModelForSeq2SeqLM</code>)           \u2013            <p>The Hugging Face model for summarization.</p> </li> <li> <code>pipeline</code>               (<code>Pipeline</code>)           \u2013            <p>The Hugging Face pipeline for summarization.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>model_name</code>               (<code>str</code>)           \u2013            <p>The name of the Hugging Face model to use.</p> </li> <li> <code>summarization_length</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>The maximum length of the summary.</p> </li> <li> <code>use_gpu</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to use the GPU for inference.</p> </li> </ul>"},{"location":"reference/models/summarization/#bookacle.models.summarization.HuggingFaceSummarizationModel.tokenizer","title":"tokenizer  <code>property</code>","text":"<pre><code>tokenizer: PreTrainedTokenizerBase\n</code></pre> <p>Returns:</p> <ul> <li> <code>PreTrainedTokenizerBase</code>           \u2013            <p>The Hugging Face tokenizer used by the underlying model.</p> </li> </ul>"},{"location":"reference/models/summarization/#bookacle.models.summarization.SummarizationModelLike","title":"SummarizationModelLike","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol that defines the methods and attributes that a summarization model should implement.</p>"},{"location":"reference/models/summarization/#bookacle.models.summarization.SummarizationModelLike.tokenizer","title":"tokenizer  <code>property</code>","text":"<pre><code>tokenizer: TokenizerLike\n</code></pre> <p>Returns:</p> <ul> <li> <code>TokenizerLike</code>           \u2013            <p>The tokenizer used by the model.</p> </li> </ul>"},{"location":"reference/models/summarization/#bookacle.models.summarization.SummarizationModelLike.summarize","title":"summarize","text":"<pre><code>summarize(text: str | list[str]) -&gt; str | list[str]\n</code></pre> <p>Summarize the input text or list of texts.</p> <p>Parameters:</p> <ul> <li> <code>text</code>               (<code>str | list[str]</code>)           \u2013            <p>The input text or list of input texts to summarize.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str | list[str]</code>           \u2013            <p>The summary of the input text or list of texts.</p> </li> </ul>"},{"location":"reference/tree/","title":"bookacle.tree","text":""},{"location":"reference/tree/#bookacle.tree","title":"tree","text":""},{"location":"reference/tree/builder/","title":"bookacle.tree.builder","text":""},{"location":"reference/tree/builder/#bookacle.tree.builder","title":"builder","text":""},{"location":"reference/tree/builder/#bookacle.tree.builder.ClusterTreeBuilder","title":"ClusterTreeBuilder","text":"<pre><code>ClusterTreeBuilder(config: ClusterTreeConfig)\n</code></pre> <p>A RAPTOR tree builder that clusters nodes at each subsequent tree layer to build the tree.</p> <p>It implements the TreeBuilderLike protocol.</p> <p>Attributes:</p> <ul> <li> <code>config</code>               (<code>RaptorTreeConfig</code>)           \u2013            <p>The configuration for the tree builder.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>config</code>               (<code>ClusterTreeConfig</code>)           \u2013            <p>The configuration for the tree builder.</p> </li> </ul>"},{"location":"reference/tree/builder/#bookacle.tree.builder.ClusterTreeBuilder.build_from_documents","title":"build_from_documents","text":"<pre><code>build_from_documents(\n    documents: list[Document],\n    chunk_size: int | None = None,\n    chunk_overlap: int | None = None,\n) -&gt; Tree\n</code></pre> <p>Build a RAPTOR tree from the given documents.</p> <p>Each document is split into chunks and each chunk is embedded. These are then passed to the construct_tree() method to build the tree.</p> <p>Parameters:</p> <ul> <li> <code>documents</code>               (<code>list[Document]</code>)           \u2013            <p>The documents to build the tree from.</p> </li> <li> <code>chunk_size</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The size of the chunks to split the documents into.         When <code>None</code>, it defaults to the maximum length supported by the embedding model.</p> </li> <li> <code>chunk_overlap</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The overlap between the chunks. When <code>None</code>, it defaults to half the chunk size.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tree</code>           \u2013            <p>A RAPTOR tree built from the documents.</p> </li> </ul>"},{"location":"reference/tree/builder/#bookacle.tree.builder.ClusterTreeBuilder.construct_tree","title":"construct_tree","text":"<pre><code>construct_tree(\n    chunks: list[Document],\n    embeddings: list[list[float]],\n    reduction_dimension: int = 10,\n) -&gt; Tree\n</code></pre> <p>Construct a RAPTOR tree from the given chunks and embeddings.</p> <p>The tree is built in a bottom-up manner, starting from the leaf nodes and going up to the root nodes.</p> To build the tree <ul> <li>The leaf nodes are created from the chunks and embeddings.</li> <li>The leaf nodes are clustered to create the next tree level using create_next_tree_level().</li> <li>The process is repeated until the maximum number of layers is reached or the number of nodes in the next level is less than the reduction dimension.</li> </ul> <p>Parameters:</p> <ul> <li> <code>chunks</code>               (<code>list[Document]</code>)           \u2013            <p>The chunks to construct the tree from.</p> </li> <li> <code>embeddings</code>               (<code>list[list[float]]</code>)           \u2013            <p>The embeddings of the chunks.</p> </li> <li> <code>reduction_dimension</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>The dimension to reduce the embeddings to before clustering.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tree</code>           \u2013            <p>A RAPTOR tree constructed from the chunks and embeddings.</p> </li> </ul>"},{"location":"reference/tree/builder/#bookacle.tree.builder.ClusterTreeBuilder.create_leaf_nodes","title":"create_leaf_nodes","text":"<pre><code>create_leaf_nodes(\n    chunks: list[Document], embeddings: list[list[float]]\n) -&gt; dict[int, Node]\n</code></pre> <p>Create leaf nodes from the given chunks.</p> <p>Parameters:</p> <ul> <li> <code>chunks</code>               (<code>list[Document]</code>)           \u2013            <p>The chunks to create the leaf nodes from.</p> </li> <li> <code>embeddings</code>               (<code>list[list[float]]</code>)           \u2013            <p>The embeddings of the chunks.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict[int, Node]</code>           \u2013            <p>A mapping of the global index to the created leaf nodes.</p> </li> </ul>"},{"location":"reference/tree/builder/#bookacle.tree.builder.ClusterTreeBuilder.create_next_tree_level","title":"create_next_tree_level","text":"<pre><code>create_next_tree_level(\n    clusters: list[list[Node]],\n    first_node_index: int,\n    layer: int,\n) -&gt; dict[int, Node]\n</code></pre> <p>Create the next tree level from the given clusters.</p> For each cluster <ul> <li>The texts of the nodes in the cluster are concatenated.</li> <li>The concatenated text is summarized.</li> <li>The summarized text is embedded.</li> <li>A Node is created with the summarized text, embeddings, and the indices of the children nodes.</li> </ul> <p>Parameters:</p> <ul> <li> <code>clusters</code>               (<code>list[list[Node]]</code>)           \u2013            <p>The clusters to create the next tree level from.</p> </li> <li> <code>first_node_index</code>               (<code>int</code>)           \u2013            <p>The global index of the first node in the new layer.</p> </li> <li> <code>layer</code>               (<code>int</code>)           \u2013            <p>The layer of the tree the clusters belong to.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict[int, Node]</code>           \u2013            <p>A mapping of the global indices to the created nodes.</p> </li> </ul>"},{"location":"reference/tree/builder/#bookacle.tree.builder.TreeBuilderLike","title":"TreeBuilderLike","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol that defines the interface for a RAPTOR tree builder.</p>"},{"location":"reference/tree/builder/#bookacle.tree.builder.TreeBuilderLike.build_from_documents","title":"build_from_documents","text":"<pre><code>build_from_documents(\n    documents: list[Document],\n    chunk_size: int | None = None,\n    chunk_overlap: int | None = None,\n    *args,\n    **kwargs\n) -&gt; Tree\n</code></pre> <p>Build a tree from a list of documents.</p> <p>Parameters:</p> <ul> <li> <code>documents</code>               (<code>list[Document]</code>)           \u2013            <p>A list of documents to build the tree from.</p> </li> <li> <code>chunk_size</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The size of the chunks to split the documents into.</p> </li> <li> <code>chunk_overlap</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The overlap between the chunks.</p> </li> <li> <code>*args</code>           \u2013            <p>Additional positional arguments.</p> </li> <li> <code>**kwargs</code>           \u2013            <p>Additional keyword arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tree</code>           \u2013            <p>A tree built from the documents.</p> </li> </ul>"},{"location":"reference/tree/clustering/","title":"bookacle.tree.clustering","text":""},{"location":"reference/tree/clustering/#bookacle.tree.clustering","title":"clustering","text":"<p>Clustering module for the tree structure.</p>"},{"location":"reference/tree/clustering/#bookacle.tree.clustering.ClusteringBackendLike","title":"ClusteringBackendLike","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol that defines the interface a clustering backend should implement.</p>"},{"location":"reference/tree/clustering/#bookacle.tree.clustering.ClusteringBackendLike.cluster","title":"cluster","text":"<pre><code>cluster(\n    embeddings: NDArray[float64], *args, **kwargs\n) -&gt; tuple[dict[int, list[int]], dict[int, list[int]]]\n</code></pre> <p>Cluster the embeddings.</p> <p>Parameters:</p> <ul> <li> <code>embeddings</code>               (<code>NDArray[float64]</code>)           \u2013            <p>The embeddings to cluster.</p> </li> <li> <code>*args</code>           \u2013            <p>Additional arguments to pass to the clustering function.</p> </li> <li> <code>**kwargs</code>           \u2013            <p>Additional keyword arguments to pass to the clustering function.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict[int, list[int]]</code>           \u2013            <p>The mapping of embeddings to clusters</p> </li> <li> <code>dict[int, list[int]]</code>           \u2013            <p>The mapping of clusters to embeddings.</p> </li> </ul>"},{"location":"reference/tree/clustering/#bookacle.tree.clustering.ClusteringFunctionLike","title":"ClusteringFunctionLike","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol that defines the interface a clustering function should implement.</p>"},{"location":"reference/tree/clustering/#bookacle.tree.clustering.ClusteringFunctionLike.__call__","title":"__call__","text":"<pre><code>__call__(\n    nodes: list[Node],\n    tokenizer: TokenizerLike,\n    clustering_backend: ClusteringBackendLike | None = None,\n    max_length_in_cluster: int = 3500,\n    reduction_dimension: int = 10,\n    *args,\n    **kwargs\n) -&gt; list[list[Node]]\n</code></pre> <p>Cluster nodes using the given clustering backend.</p> <p>Parameters:</p> <ul> <li> <code>nodes</code>               (<code>list[Node]</code>)           \u2013            <p>The nodes to cluster.</p> </li> <li> <code>tokenizer</code>               (<code>TokenizerLike</code>)           \u2013            <p>The tokenizer to use to calculate the total length of text in each cluster.</p> </li> <li> <code>clustering_backend</code>               (<code>ClusteringBackendLike | None</code>, default:                   <code>None</code> )           \u2013            <p>The clustering backend to use.</p> </li> <li> <code>max_length_in_cluster</code>               (<code>int</code>, default:                   <code>3500</code> )           \u2013            <p>The maximum length of text in a cluster.</p> </li> <li> <code>reduction_dimension</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>The dimension to reduce the embeddings to before clustering.</p> </li> <li> <code>*args</code>           \u2013            <p>Additional arguments to pass to the clustering function.</p> </li> <li> <code>**kwargs</code>           \u2013            <p>Additional keyword arguments to pass to the clustering function.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[list[Node]]</code>           \u2013            <p>The clustered nodes.</p> </li> </ul>"},{"location":"reference/tree/clustering/#bookacle.tree.clustering.GMMClusteringBackend","title":"GMMClusteringBackend","text":"<pre><code>GMMClusteringBackend(\n    reduction_dim: int,\n    max_clusters: int = 50,\n    random_state: int = 42,\n    n_neighbors_global: int | None = None,\n    n_neighbors_local: int = 10,\n    n_clusters_global: int | None = None,\n    n_clusters_local: int | None = None,\n    umap_metric: str = \"cosine\",\n    umap_low_memory: bool = True,\n)\n</code></pre> <p>A Gaussian Mixture Model (GMM) clustering backend.</p> <p>It implements the ClusteringBackendLike protocol.</p> <p>Attributes:</p> <ul> <li> <code>reduction_dim</code>               (<code>int</code>)           \u2013            <p>The dimension to reduce the embeddings to before clustering.</p> </li> <li> <code>max_clusters</code>               (<code>int</code>)           \u2013            <p>The maximum number of clusters to use.</p> </li> <li> <code>random_state</code>               (<code>int</code>)           \u2013            <p>Random state for reproducibility.</p> </li> <li> <code>n_neighbors_global</code>               (<code>int | None</code>)           \u2013            <p>The number of neighbors to use for global clustering.</p> </li> <li> <code>n_neighbors_local</code>               (<code>int | None</code>)           \u2013            <p>The number of neighbors to use for local clustering.</p> </li> <li> <code>n_clusters_global</code>               (<code>int | None</code>)           \u2013            <p>The number of clusters to use for global clustering.</p> </li> <li> <code>n_clusters_local</code>               (<code>int | None</code>)           \u2013            <p>The number of clusters to use for local clustering.</p> </li> <li> <code>umap_metric</code>               (<code>str</code>)           \u2013            <p>The metric to use for UMAP.</p> </li> <li> <code>umap_low_memory</code>               (<code>bool</code>)           \u2013            <p>Whether to use low memory mode for UMAP.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>reduction_dim</code>               (<code>int</code>)           \u2013            <p>The dimension to reduce the embeddings to before clustering.</p> </li> <li> <code>max_clusters</code>               (<code>int</code>, default:                   <code>50</code> )           \u2013            <p>The maximum number of clusters to use.</p> </li> <li> <code>random_state</code>               (<code>int</code>, default:                   <code>42</code> )           \u2013            <p>Random state for reproducibility.</p> </li> <li> <code>n_neighbors_global</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The number of neighbors to use for global clustering.                 When <code>None</code>, it is calculated using Bayesian Information Criterion (BIC).</p> </li> <li> <code>n_neighbors_local</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>The number of neighbors to use for local clustering.                 When <code>None</code>, it is calculated using Bayesian Information Criterion (BIC).</p> </li> <li> <code>n_clusters_global</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The number of clusters to use for global clustering.</p> </li> <li> <code>n_clusters_local</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The number of clusters to use for local clustering.</p> </li> <li> <code>umap_metric</code>               (<code>str</code>, default:                   <code>'cosine'</code> )           \u2013            <p>The metric to use for UMAP.</p> </li> <li> <code>umap_low_memory</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to use low memory mode for UMAP.</p> </li> </ul>"},{"location":"reference/tree/clustering/#bookacle.tree.clustering.GMMClusteringBackend.cluster","title":"cluster","text":"<pre><code>cluster(\n    embeddings: NDArray[float64],\n) -&gt; tuple[dict[int, list[int]], dict[int, list[int]]]\n</code></pre> <p>Cluster the embeddings.</p> The clustering is done as follows <ul> <li>Global clustering: The embeddings are reduced and clustered globally.                      That is, the entire set of embeddings is clustered.</li> <li>Local clustering: The embeddings of each global cluster are reduced and clustered.</li> <li>At the end, all local clusters are aggregated into a single result.</li> </ul> <p>Parallel from <code>joblib</code> is used to parallelize the clustering of each global cluster.</p> <p>Parameters:</p> <ul> <li> <code>embeddings</code>               (<code>NDArray[float64]</code>)           \u2013            <p>The embeddings to cluster.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict[int, list[int]]</code>           \u2013            <p>A mapping of embeddings to clusters</p> </li> <li> <code>dict[int, list[int]]</code>           \u2013            <p>A mapping of clusters to embeddings.</p> </li> </ul> <p>Examples:</p> <pre><code>import numpy as np\nfrom bookacle.tree.clustering import GMMClusteringBackend\n\nbackend = GMMClusteringBackend(reduction_dim=10, n_clusters_global=3)\nembeddings = np.random.rand(10, 768)\nemb_to_clusters, clusters_to_emb = backend.cluster(embeddings=embeddings)\nprint(clusters_to_emb)\n</code></pre> <pre><code>defaultdict(&lt;class 'list'&gt;, {0: [2, 3, 8, 9], 1: [1, 6, 7], 2: [0, 4, 5]})\n</code></pre>"},{"location":"reference/tree/clustering/#bookacle.tree.clustering.GMMClusteringBackend.cluster_locally","title":"cluster_locally","text":"<pre><code>cluster_locally(\n    embeddings: NDArray[float64],\n    global_cluster_indices: NDArray[int64],\n    n_clusters: int | None = None,\n    n_neighbors: int = 10,\n) -&gt; list[NDArray[int64]]\n</code></pre> <p>Cluster the embeddings of a global cluster locally. In other words, create new clusters from the embeddings of a global cluster.</p> <p>If the number of embeddings in the global cluster is less than or equal to <code>reduction_dim</code>, the global cluster is returned as is in a singleton list.</p> <p>Parameters:</p> <ul> <li> <code>embeddings</code>               (<code>NDArray[float64]</code>)           \u2013            <p>The overall embeddings.</p> </li> <li> <code>global_cluster_indices</code>               (<code>NDArray[int64]</code>)           \u2013            <p>The indices of the embeddings belonging to the global cluster.</p> </li> <li> <code>n_clusters</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The number of clusters to output.         When <code>None</code>, the optimal number of clusters is calculated using BIC.</p> </li> <li> <code>n_neighbors</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>The number of neighbors to use for UMAP.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[NDArray[int64]]</code>           \u2013            <p>The local clusters.</p> </li> </ul> <p>Examples:</p> <pre><code>import numpy as np\nfrom bookacle.tree.clustering import GMMClusteringBackend\n\nbackend = GMMClusteringBackend(reduction_dim=10)\nembeddings = np.random.rand(100, 768)\nindices = np.random.choice(100, 30)\nclusters = backend.cluster_locally(\n    embeddings=embeddings,\n    global_cluster_indices=indices,\n    n_clusters=5,\n    n_neighbors=10,\n)\nprint(clusters)\n</code></pre> <pre><code>[array([83,  8, 86, 17,  0, 12, 86, 70]), array([61, 96, 76, 61, 22, 10, 81, 71, 42]), array([27,  6, 39, 78, 92, 85]), array([46, 46, 30, 82]), array([57, 91, 91])]\n</code></pre>"},{"location":"reference/tree/clustering/#bookacle.tree.clustering.GMMClusteringBackend.get_clusters","title":"get_clusters","text":"<pre><code>get_clusters(\n    embeddings: NDArray[float64], n_clusters: int\n) -&gt; NDArray[int64]\n</code></pre> <p>Fit the GMM model to embeddings and return cluster assignments.</p> <p>Parameters:</p> <ul> <li> <code>embeddings</code>               (<code>NDArray[float64]</code>)           \u2013            <p>The embeddings to cluster.</p> </li> <li> <code>n_clusters</code>               (<code>int</code>)           \u2013            <p>The number of clusters to use.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray[int64]</code>           \u2013            <p>The cluster assignments.</p> </li> </ul>"},{"location":"reference/tree/clustering/#bookacle.tree.clustering.GMMClusteringBackend.get_optimal_clusters_count","title":"get_optimal_clusters_count","text":"<pre><code>get_optimal_clusters_count(\n    embeddings: NDArray[float64],\n) -&gt; int\n</code></pre> <p>Get the optimal number of clusters using the Bayesian Information Criterion (BIC).</p> <p>The method fits multiple Gaussian Mixture Models (GMM) to the embeddings and calculates the BIC for each. The number of clusters with the lowest BIC score is selected as the optimal number.</p> <p>Parameters:</p> <ul> <li> <code>embeddings</code>               (<code>NDArray[float64]</code>)           \u2013            <p>The embeddings to cluster.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>The optimal number of clusters.</p> </li> </ul>"},{"location":"reference/tree/clustering/#bookacle.tree.clustering.GMMClusteringBackend.reduce_and_cluster_embeddings","title":"reduce_and_cluster_embeddings","text":"<pre><code>reduce_and_cluster_embeddings(\n    embeddings: NDArray[float64],\n    n_components: int,\n    n_neighbors: int,\n    n_clusters: int | None = None,\n) -&gt; NDArray[int64]\n</code></pre> <p>Reduce the dimensionality of the embeddings using UMAP and cluster them using GMM.</p> <p>It uses umap_reduce_embeddings() to reduce the dimensionality of the embeddings and get_clusters() to cluster them.</p> <p>Generally speaking, this method should be used instead of calling get_clusters() directly.</p> <p>Parameters:</p> <ul> <li> <code>embeddings</code>               (<code>NDArray[float64]</code>)           \u2013            <p>The embeddings to cluster.</p> </li> <li> <code>n_components</code>               (<code>int</code>)           \u2013            <p>The number of components in the reduced space.</p> </li> <li> <code>n_neighbors</code>               (<code>int</code>)           \u2013            <p>The number of neighbors to use for UMAP.</p> </li> <li> <code>n_clusters</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The number of clusters to use. When <code>None</code>, the optimal number of clusters is         calculated using         get_optimal_clusters_count().</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray[int64]</code>           \u2013            <p>The cluster assignments.</p> </li> </ul>"},{"location":"reference/tree/clustering/#bookacle.tree.clustering.raptor_clustering","title":"raptor_clustering","text":"<pre><code>raptor_clustering(\n    nodes: list[Node],\n    tokenizer: TokenizerLike,\n    clustering_backend: ClusteringBackendLike | None = None,\n    max_length_in_cluster: int = 3500,\n    reduction_dimension: int = 10,\n) -&gt; list[list[Node]]\n</code></pre> <p>Cluster nodes using RAPTOR clustering.</p> <p>It implements the ClusteringFunctionLike protocol.</p> To cluster the nodes <ul> <li>The nodes are clustered using the given clustering backend.</li> <li>For each cluster:<ul> <li>If the cluster has only one node or the total length of text in the cluster is less than the maximum length, the cluster is kept as is.</li> <li>Otherwise, the cluster is recursively clustered.</li> </ul> </li> </ul>"},{"location":"reference/tree/clustering/#bookacle.tree.clustering.umap_reduce_embeddings","title":"umap_reduce_embeddings","text":"<pre><code>umap_reduce_embeddings(\n    embeddings: NDArray[float64],\n    n_components: int,\n    neighbors: int = 10,\n    metric: str = \"cosine\",\n    low_memory: bool = True,\n) -&gt; NDArray[float64]\n</code></pre> <p>Reduce the dimensionality of the embeddings using UMAP.</p> <p>Parameters:</p> <ul> <li> <code>embeddings</code>               (<code>NDArray[float64]</code>)           \u2013            <p>The embeddings to reduce.</p> </li> <li> <code>n_components</code>               (<code>int</code>)           \u2013            <p>The number of components in the reduced space.</p> </li> <li> <code>neighbors</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>The number of neighbors to use for UMAP.</p> </li> <li> <code>metric</code>               (<code>str</code>, default:                   <code>'cosine'</code> )           \u2013            <p>The metric to use for UMAP.</p> </li> <li> <code>low_memory</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to use low memory mode for UMAP.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray[float64]</code>           \u2013            <p>The reduced embeddings.</p> </li> </ul>"},{"location":"reference/tree/config/","title":"bookacle.tree.config","text":""},{"location":"reference/tree/config/#bookacle.tree.config","title":"config","text":""},{"location":"reference/tree/config/#bookacle.tree.config.ClusterTreeConfig","title":"ClusterTreeConfig  <code>dataclass</code>","text":"<pre><code>ClusterTreeConfig(\n    embedding_model: EmbeddingModelLike,\n    summarization_model: SummarizationModelLike,\n    document_splitter: DocumentSplitterLike,\n    clustering_func: ClusteringFunctionLike = raptor_clustering,\n    clustering_backend: ClusteringBackendLike | None = None,\n    max_length_in_cluster: int = 3500,\n    max_num_layers: int = 5,\n)\n</code></pre> <p>Configuration for ClusterTreeBuilder.</p> <p>Parameters:</p> <ul> <li> <code>embedding_model</code>               (<code>EmbeddingModelLike</code>)           \u2013            <p>The embedding model to use.</p> </li> <li> <code>summarization_model</code>               (<code>SummarizationModelLike</code>)           \u2013            <p>The summarization model to use.</p> </li> <li> <code>document_splitter</code>               (<code>DocumentSplitterLike</code>)           \u2013            <p>The document splitter to use.</p> </li> <li> <code>clustering_func</code>               (<code>ClusteringFunctionLike</code>, default:                   <code>raptor_clustering</code> )           \u2013            <p>The clustering function to use.</p> </li> <li> <code>clustering_backend</code>               (<code>ClusteringBackendLike | None</code>, default:                   <code>None</code> )           \u2013            <p>The clustering backend to use.</p> </li> <li> <code>max_length_in_cluster</code>               (<code>int</code>, default:                   <code>3500</code> )           \u2013            <p>The maximum length of a cluster.</p> </li> <li> <code>max_num_layers</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>The maximum number of layers</p> </li> </ul>"},{"location":"reference/tree/config/#bookacle.tree.config.ClusterTreeConfig.embedding_tokenizer","title":"embedding_tokenizer  <code>property</code>","text":"<pre><code>embedding_tokenizer: TokenizerLike\n</code></pre> <p>Returns:</p> <ul> <li> <code>TokenizerLike</code>           \u2013            <p>The tokenizer of the embedding model.</p> </li> </ul>"},{"location":"reference/tree/config/#bookacle.tree.config.ClusterTreeConfig.summarization_tokenizer","title":"summarization_tokenizer  <code>property</code>","text":"<pre><code>summarization_tokenizer: TokenizerLike\n</code></pre> <p>Returns:</p> <ul> <li> <code>TokenizerLike</code>           \u2013            <p>The tokenizer of the summarization model.</p> </li> </ul>"},{"location":"reference/tree/config/#bookacle.tree.config.SelectionMode","title":"SelectionMode","text":"<p>               Bases: <code>Enum</code></p> <p>Selection modes supported by the retriever.</p>"},{"location":"reference/tree/config/#bookacle.tree.config.SelectionMode.THRESHOLD","title":"THRESHOLD  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>THRESHOLD = 'threshold'\n</code></pre> <p>Selection using a threshold value on the distance.</p>"},{"location":"reference/tree/config/#bookacle.tree.config.SelectionMode.TOP_K","title":"TOP_K  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TOP_K = 'top_k'\n</code></pre> <p>Selection using Top K.</p>"},{"location":"reference/tree/config/#bookacle.tree.config.TreeRetrieverConfig","title":"TreeRetrieverConfig  <code>dataclass</code>","text":"<pre><code>TreeRetrieverConfig(\n    embedding_model: EmbeddingModelLike,\n    threshold: float = 0.5,\n    top_k: int = 5,\n    selection_mode: SelectionMode = SelectionMode.TOP_K,\n    max_tokens: int = 3500,\n)\n</code></pre> <p>Configuration for TreeRetriever.</p> <p>Parameters:</p> <ul> <li> <code>embedding_model</code>               (<code>EmbeddingModelLike</code>)           \u2013            <p>The embedding model to use.</p> </li> <li> <code>threshold</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>The threshold value for selection when using threshold mode for selection.</p> </li> <li> <code>top_k</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>The number of top results to return when using top k mode for selection.</p> </li> <li> <code>selection_mode</code>               (<code>SelectionMode</code>, default:                   <code>TOP_K</code> )           \u2013            <p>The selection mode to use.</p> </li> <li> <code>max_tokens</code>               (<code>int</code>, default:                   <code>3500</code> )           \u2013            <p>The maximum number of tokens to retrieve.</p> </li> </ul>"},{"location":"reference/tree/config/#bookacle.tree.config.TreeRetrieverConfig.tokenizer","title":"tokenizer  <code>property</code>","text":"<pre><code>tokenizer: TokenizerLike\n</code></pre> <p>Returns:</p> <ul> <li> <code>TokenizerLike</code>           \u2013            <p>The tokenizer of the embedding model.</p> </li> </ul>"},{"location":"reference/tree/retriever/","title":"bookacle.tree.retriever","text":""},{"location":"reference/tree/retriever/#bookacle.tree.retriever","title":"retriever","text":""},{"location":"reference/tree/retriever/#bookacle.tree.retriever.RetrieverLike","title":"RetrieverLike","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol that defines the interface for a tree retriever.</p>"},{"location":"reference/tree/retriever/#bookacle.tree.retriever.RetrieverLike.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    query: str, tree: Tree, *args, **kwargs\n) -&gt; tuple[list[Node], str]\n</code></pre> <p>Retrieve relevant nodes from a tree given a query.</p> <p>Parameters:</p> <ul> <li> <code>query</code>               (<code>str</code>)           \u2013            <p>The query to retrieve nodes for.</p> </li> <li> <code>tree</code>               (<code>Tree</code>)           \u2013            <p>The tree to retrieve nodes from.</p> </li> <li> <code>*args</code>           \u2013            <p>Additional positional arguments.</p> </li> <li> <code>**kwargs</code>           \u2013            <p>Additional keyword arguments.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[Node]</code>           \u2013            <p>The retrieved nodes.</p> </li> <li> <code>str</code>           \u2013            <p>The concatenated text of the retrieved nodes.</p> </li> </ul>"},{"location":"reference/tree/retriever/#bookacle.tree.retriever.TreeRetriever","title":"TreeRetriever","text":"<pre><code>TreeRetriever(config: TreeRetrieverConfig)\n</code></pre> <p>A tree retriever that retrieves relevant nodes from a tree given a query.</p> <p>It implements the RetrieverLike protocol.</p> <p>Attributes:</p> <ul> <li> <code>config</code>               (<code>TreeRetrieverConfig</code>)           \u2013            <p>The configuration for the retriever.</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>config</code>               (<code>TreeRetrieverConfig</code>)           \u2013            <p>The configuration for the retriever.</p> </li> </ul>"},{"location":"reference/tree/retriever/#bookacle.tree.retriever.TreeRetriever.get_nodes_within_context","title":"get_nodes_within_context","text":"<pre><code>get_nodes_within_context(\n    candidate_nodes: list[Node],\n) -&gt; list[Node]\n</code></pre> <p>Filter candidate nodes to those that fit within the maximum token length.</p> <p>Parameters:</p> <ul> <li> <code>candidate_nodes</code>               (<code>list[Node]</code>)           \u2013            <p>The candidate nodes to filter.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[Node]</code>           \u2013            <p>The filtered candidate nodes.</p> </li> </ul>"},{"location":"reference/tree/retriever/#bookacle.tree.retriever.TreeRetriever.get_relevant_node_indices","title":"get_relevant_node_indices","text":"<pre><code>get_relevant_node_indices(\n    target_embedding: list[float],\n    candidate_nodes: list[Node],\n) -&gt; NDArray[int64]\n</code></pre> <p>Get the relevant node indices given a target embedding and candidate nodes.</p> Nodes are selected in the following manner <ul> <li>The cosine similarity between the target embedding and the candidate node embeddings is computed.</li> <li>The cosine similarities are sorted in descending order.</li> <li>If the selection mode is   SelectionMode.TOP_K, the top <code>k</code> nodes are selected.</li> <li>If the selection mode is   SelectionMode.THRESHOLD,   the nodes with cosine similarity greater than the threshold are selected.</li> </ul> <p>Parameters:</p> <ul> <li> <code>target_embedding</code>               (<code>list[float]</code>)           \u2013            <p>The target embedding to compare against.</p> </li> <li> <code>candidate_nodes</code>               (<code>list[Node]</code>)           \u2013            <p>The candidate nodes to compare against.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray[int64]</code>           \u2013            <p>The relevant node indices.</p> </li> </ul>"},{"location":"reference/tree/retriever/#bookacle.tree.retriever.TreeRetriever.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    query: str,\n    tree: Tree,\n    start_layer: int | None = None,\n    end_layer: int | None = None,\n    collapse_tree: bool = True,\n) -&gt; tuple[list[Node], str]\n</code></pre> <p>Retrieve relevant nodes from a tree given a query.</p> <p>Parameters:</p> <ul> <li> <code>query</code>               (<code>str</code>)           \u2013            <p>The query to retrieve nodes for.</p> </li> <li> <code>tree</code>               (<code>Tree</code>)           \u2013            <p>The tree to retrieve nodes from.</p> </li> <li> <code>start_layer</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The layer to start retrieving nodes from. When <code>None</code>, the root layer is used.</p> </li> <li> <code>end_layer</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>The layer to stop retrieving nodes at. When <code>None</code>, the leaf layer is used.</p> </li> <li> <code>collapse_tree</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to use the collapsed tree strategy.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[Node]</code>           \u2013            <p>The retrieved nodes.</p> </li> <li> <code>str</code>           \u2013            <p>The concatenated text of the retrieved nodes</p> </li> </ul>"},{"location":"reference/tree/retriever/#bookacle.tree.retriever.TreeRetriever.retrieve_collapse","title":"retrieve_collapse","text":"<pre><code>retrieve_collapse(\n    query: str, tree: Tree\n) -&gt; tuple[list[Node], str]\n</code></pre> <p>Retrieve relevant nodes from a tree given a query using the collapsed tree strategy.</p> <p>For more details about the collapsed tree strategy, refer to the RAPTOR paper: https://arxiv.org/pdf/2401.18059.</p> The retrieved nodes are selected in the following manner <ul> <li>The query is embedded using the embedding model.</li> <li>The candidate nodes are all the nodes in the tree.</li> <li>Relevant nodes are retrieved using   get_relevant_node_indices().</li> <li>The nodes are filtered to fit within the maximum token length using   get_nodes_within_context().</li> </ul> <p>Parameters:</p> <ul> <li> <code>query</code>               (<code>str</code>)           \u2013            <p>The query to retrieve nodes for.</p> </li> <li> <code>tree</code>               (<code>Tree</code>)           \u2013            <p>The tree to retrieve nodes from.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[Node]</code>           \u2013            <p>The retrieved nodes.</p> </li> <li> <code>str</code>           \u2013            <p>The concatenated text of the retrieved nodes.</p> </li> </ul>"},{"location":"reference/tree/retriever/#bookacle.tree.retriever.TreeRetriever.retrieve_no_collapse","title":"retrieve_no_collapse","text":"<pre><code>retrieve_no_collapse(\n    query: str, tree: Tree, start_layer: int, end_layer: int\n) -&gt; tuple[list[Node], str]\n</code></pre> <p>Retrieve relevant nodes from a tree given a query using the tree traversal strategy.</p> <p>For more details about the collapsed tree strategy, refer to the RAPTOR paper: https://arxiv.org/pdf/2401.18059.</p> The retrieved nodes are selected in the following manner <ul> <li>The query is embedded using the embedding model.</li> <li>The candidate nodes are all the nodes in the tree from the start layer to the end layer.</li> <li>For each layer<ul> <li>Relevant nodes are retrieved using   get_relevant_node_indices().</li> <li>The process is repeated on the children of the relevant nodes until the end layer is reached   or no more children are available.</li> </ul> </li> <li>The nodes are filtered to fit within the maximum token length using</li> </ul> <p>Parameters:</p> <ul> <li> <code>query</code>               (<code>str</code>)           \u2013            <p>The query to retrieve nodes for.</p> </li> <li> <code>tree</code>               (<code>Tree</code>)           \u2013            <p>The tree to retrieve nodes from.</p> </li> <li> <code>start_layer</code>               (<code>int</code>)           \u2013            <p>The layer to start retrieving nodes from.</p> </li> <li> <code>end_layer</code>               (<code>int</code>)           \u2013            <p>The layer to stop retrieving nodes at.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[Node]</code>           \u2013            <p>The retrieved nodes.</p> </li> <li> <code>str</code>           \u2013            <p>The concatenated text of the retrieved nodes.</p> </li> </ul>"},{"location":"reference/tree/structures/","title":"bookacle.tree.structures","text":""},{"location":"reference/tree/structures/#bookacle.tree.structures","title":"structures","text":""},{"location":"reference/tree/structures/#bookacle.tree.structures.Node","title":"Node  <code>dataclass</code>","text":"<pre><code>Node(\n    text: str,\n    index: int,\n    children: set[int],\n    embeddings: list[float],\n    metadata: dict[str, Any] | None = None,\n    layer: int = 0,\n)\n</code></pre> <p>A node in the RAPTOR tree.</p> <p>Attributes:</p> <ul> <li> <code>text</code>               (<code>str</code>)           \u2013            <p>The text of the node.</p> </li> <li> <code>index</code>               (<code>int</code>)           \u2013            <p>The global index of the node in the tree.</p> </li> <li> <code>children</code>               (<code>set[int]</code>)           \u2013            <p>The global indices of the children nodes.</p> </li> <li> <code>embeddings</code>               (<code>list[float]</code>)           \u2013            <p>Embeddings of the node\u2019s text.</p> </li> <li> <code>metadata</code>               (<code>dict[str, Any] | None</code>)           \u2013            <p>Metadata about the node\u2019s text.</p> </li> <li> <code>layer</code>               (<code>int</code>)           \u2013            <p>Tree layer the node belongs to.</p> </li> </ul>"},{"location":"reference/tree/structures/#bookacle.tree.structures.Node.num_children","title":"num_children  <code>property</code>","text":"<pre><code>num_children: int\n</code></pre> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>Number of children nodes.</p> </li> </ul>"},{"location":"reference/tree/structures/#bookacle.tree.structures.Node.from_children","title":"from_children  <code>classmethod</code>","text":"<pre><code>from_children(\n    children: list[Node],\n    embedding_model: EmbeddingModelLike,\n    summarization_model: SummarizationModelLike,\n    index: int,\n    layer: int = 0,\n) -&gt; Node\n</code></pre> <p>Create a node from a list of children nodes by summarizing their texts.</p> <p>The text of the children nodes is concatenated using concatenate_node_texts() and passed to the summarization model to generate a summary.</p> <p>Parameters:</p> <ul> <li> <code>children</code>               (<code>list[Node]</code>)           \u2013            <p>A list of children nodes.</p> </li> <li> <code>embedding_model</code>               (<code>EmbeddingModelLike</code>)           \u2013            <p>The embedding model to use for embedding the summarized text.</p> </li> <li> <code>summarization_model</code>               (<code>SummarizationModelLike</code>)           \u2013            <p>The summarization model to use for summarizing                  the text of the children nodes.</p> </li> <li> <code>index</code>               (<code>int</code>)           \u2013            <p>The global index of the node in the tree.</p> </li> <li> <code>layer</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Tree layer the node belongs to.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Node</code>           \u2013            <p>A node created from the children nodes.</p> </li> </ul>"},{"location":"reference/tree/structures/#bookacle.tree.structures.Node.from_text","title":"from_text  <code>classmethod</code>","text":"<pre><code>from_text(\n    index: int,\n    text: str,\n    embedding_model: EmbeddingModelLike,\n    children_indices: set[int] | None = None,\n    metadata: dict[str, str] | None = None,\n    layer: int = 0,\n) -&gt; Node\n</code></pre> <p>Create a node from text by embedding it using the given embedding model.</p> <p>Parameters:</p> <ul> <li> <code>index</code>               (<code>int</code>)           \u2013            <p>The global index of the node in the tree.</p> </li> <li> <code>text</code>               (<code>str</code>)           \u2013            <p>The text of the node.</p> </li> <li> <code>embedding_model</code>               (<code>EmbeddingModelLike</code>)           \u2013            <p>The embedding model to use for embedding the text.</p> </li> <li> <code>children_indices</code>               (<code>set[int] | None</code>, default:                   <code>None</code> )           \u2013            <p>The global indices of the children nodes.</p> </li> <li> <code>metadata</code>               (<code>dict[str, str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Metadata about the node\u2019s text.</p> </li> <li> <code>layer</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Tree layer the node belongs to.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Node</code>           \u2013            <p>A node created from the text.</p> </li> </ul>"},{"location":"reference/tree/structures/#bookacle.tree.structures.Tree","title":"Tree  <code>dataclass</code>","text":"<pre><code>Tree(\n    all_nodes: dict[int, Node],\n    root_nodes: dict[int, Node],\n    leaf_nodes: dict[int, Node],\n    num_layers: int,\n    layer_to_nodes: dict[int, list[Node]],\n)\n</code></pre> <p>A RAPTOR tree.</p> <p>Attributes:</p> <ul> <li> <code>all_nodes</code>               (<code>dict[int, Node]</code>)           \u2013            <p>All nodes in the tree, mapped to their global indices.</p> </li> <li> <code>root_nodes</code>               (<code>dict[int, Node]</code>)           \u2013            <p>Root nodes in the tree, mapped to their global indices.</p> </li> <li> <code>leaf_nodes</code>               (<code>dict[int, Node]</code>)           \u2013            <p>Leaf nodes in the tree, mapped to their global indices.</p> </li> <li> <code>num_layers</code>               (<code>int</code>)           \u2013            <p>Number of layers in the tree.</p> </li> <li> <code>layer_to_nodes</code>               (<code>dict[int, list[Node]]</code>)           \u2013            <p>Nodes in a layer, mapped to their layer index.</p> </li> </ul>"},{"location":"reference/tree/structures/#bookacle.tree.structures.Tree.num_nodes","title":"num_nodes  <code>property</code>","text":"<pre><code>num_nodes: int\n</code></pre> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>The number of nodes in the tree.</p> </li> </ul>"},{"location":"reference/tree/structures/#bookacle.tree.structures.Tree.top_layer","title":"top_layer  <code>property</code>","text":"<pre><code>top_layer: int\n</code></pre> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>Index of the root layer of the tree.</p> </li> </ul>"},{"location":"reference/tree/structures/#bookacle.tree.structures.Tree.fetch_layer","title":"fetch_layer","text":"<pre><code>fetch_layer(layer: int) -&gt; list[Node]\n</code></pre> <p>Fetch all nodes in a layer of the tree.</p> <p>Parameters:</p> <ul> <li> <code>layer</code>               (<code>int</code>)           \u2013            <p>The layer index to fetch nodes from.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[Node]</code>           \u2013            <p>List of nodes in the given layer.</p> </li> </ul>"},{"location":"reference/tree/structures/#bookacle.tree.structures.Tree.fetch_node_layer","title":"fetch_node_layer","text":"<pre><code>fetch_node_layer(node_idx: int) -&gt; int\n</code></pre> <p>Fetch the index of the layer a node belongs to in the tree.</p> <p>Parameters:</p> <ul> <li> <code>node_idx</code>               (<code>int</code>)           \u2013            <p>The global index of the node.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>The index of the layer the node belongs to.</p> </li> </ul>"},{"location":"reference/tree/structures/#bookacle.tree.structures.Tree.get_node","title":"get_node","text":"<pre><code>get_node(index: int) -&gt; Node\n</code></pre> <p>Fetch a node in the tree by its global index.</p> <p>Parameters:</p> <ul> <li> <code>index</code>               (<code>int</code>)           \u2013            <p>The global index of the node to fetch.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Node</code>           \u2013            <p>The node with the given global index.</p> </li> </ul>"},{"location":"reference/tree/structures/#bookacle.tree.structures.Tree.tolist","title":"tolist","text":"<pre><code>tolist() -&gt; list[Node]\n</code></pre> <p>Returns:</p> <ul> <li> <code>list[Node]</code>           \u2013            <p>List of all nodes in the tree.</p> </li> </ul>"},{"location":"reference/tree/structures/#bookacle.tree.structures.concatenate_node_texts","title":"concatenate_node_texts","text":"<pre><code>concatenate_node_texts(nodes: list[Node]) -&gt; str\n</code></pre> <p>Concatenate the texts of a list of nodes.</p>"}]}