{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"reference/SUMMARY/","title":"API Reference","text":"<ul> <li>bookacle<ul> <li>chat</li> <li>cli</li> <li>conf<ul> <li>config</li> </ul> </li> <li>document</li> <li>loaders</li> <li>models<ul> <li>embedding</li> <li>message</li> <li>qa</li> <li>summarization</li> </ul> </li> <li>splitters</li> <li>tokenizer</li> <li>tree<ul> <li>builder</li> <li>clustering</li> <li>config</li> <li>retriever</li> <li>structures</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/bookacle/","title":"Bookacle","text":""},{"location":"reference/bookacle/chat/","title":"Chat","text":"<p>Chat module for conversing with a RAPTOR RAG-based LLM in the terminal.</p>"},{"location":"reference/bookacle/chat/#bookacle.chat.Chat","title":"Chat","text":"<pre><code>Chat(\n    retriever,\n    qa_model,\n    console,\n    history_file=\".bookacle-chat-history.txt\",\n    user_avatar=\"\ud83d\udc64\",\n)\n</code></pre> <p>A terminal-based chat interface for interacting with a RAPTOR RAG-based LLM.</p> <p>Attributes:</p> Name Type Description <code>retriever</code> <code>RetrieverLike</code> <p>Retriever to use for retrieving relevant context.</p> <code>qa_model</code> <code>QAModelLike</code> <p>QA model to use for answering questions.</p> <code>console</code> <code>Console</code> <p>Rich Console to use for displaying messages.</p> <code>history_file</code> <code>str</code> <p>File to store chat history.</p> <code>user_avatar</code> <code>str</code> <p>Avatar to use for the user in the chat UI.</p> <p>Parameters:</p> Name Type Description Default <code>retriever</code> <code>RetrieverLike</code> <p>Retriever to use for retrieving relevant context.</p> required <code>qa_model</code> <code>QAModelLike</code> <p>QA model to use for answering questions.</p> required <code>console</code> <code>Console</code> <p>Rich Console to use for displaying messages.</p> required <code>history_file</code> <code>str</code> <p>File to store chat history. The file is created in the home directory.</p> <code>'.bookacle-chat-history.txt'</code> <code>user_avatar</code> <code>str</code> <p>Avatar to use for the user in the chat UI.</p> <code>'\ud83d\udc64'</code>"},{"location":"reference/bookacle/chat/#bookacle.chat.Chat.display_ai_msg_stream","title":"display_ai_msg_stream","text":"<pre><code>display_ai_msg_stream(messages)\n</code></pre> <p>Display an AI message stream in the chat UI.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>Iterator[Message]</code> <p>Stream of AI messages to display.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The complete message as a string.</p>"},{"location":"reference/bookacle/chat/#bookacle.chat.Chat.invoke_qa_model","title":"invoke_qa_model","text":"<pre><code>invoke_qa_model(\n    tree,\n    question,\n    history=None,\n    stream=True,\n    *args,\n    **kwargs\n)\n</code></pre> <p>Invoke the QA model to answer a question.</p> <p>Parameters:</p> Name Type Description Default <code>tree</code> <code>Tree</code> <p>RAPTOR tree that should be used for RAG.</p> required <code>question</code> <code>str</code> <p>The question to answer.</p> required <code>history</code> <code>list[Message] | None</code> <p>Chat history.</p> <code>None</code> <code>stream</code> <code>bool</code> <p>Whether to stream the AI response.</p> <code>True</code> <code>**args</code> <code>tuple[Any]</code> <p>Additional positional arguments to pass to the retriever.</p> <code>()</code> <code>**kwargs</code> <code>dict[str, Any]</code> <p>Additional keyword arguments to pass to the retriever.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Message</code> <p>The response from the QA model.</p>"},{"location":"reference/bookacle/chat/#bookacle.chat.Chat.run","title":"run","text":"<pre><code>run(\n    tree,\n    initial_chat_message=\"\",\n    system_prompt=\"\",\n    stream=True,\n    *args,\n    **kwargs\n)\n</code></pre> <p>Run the chat interface.</p> <p>Parameters:</p> Name Type Description Default <code>tree</code> <code>Tree</code> <p>RAPTOR tree that should be used for RAG.</p> required <code>initial_chat_message</code> <code>str</code> <p>Initial message to display in the chat.</p> <code>''</code> <code>system_prompt</code> <code>str</code> <p>System prompt that should be used for the QA model.</p> <code>''</code> <code>stream</code> <code>bool</code> <p>Whether to stream the AI response.</p> <code>True</code> <code>*args</code> <code>tuple[Any]</code> <p>Additional positional arguments to pass to the retriever.</p> <code>()</code> <code>**kwargs</code> <code>dict[str, Any]</code> <p>Additional keyword arguments to pass to the retriever.</p> <code>{}</code>"},{"location":"reference/bookacle/cli/","title":"Cli","text":""},{"location":"reference/bookacle/document/","title":"Document","text":"<p>This module defines the document structure used throughout the package.</p>"},{"location":"reference/bookacle/document/#bookacle.document.Document","title":"Document","text":"<p>               Bases: <code>TypedDict</code></p> <p>A TypedDict that represents a page in a PDF file.</p> <p>Attributes:</p> Name Type Description <code>page_content</code> <code>str</code> <p>The text content of the page.</p> <code>metadata</code> <code>NotRequired[dict[str, Any]]</code> <p>Additional metadata about the page.</p>"},{"location":"reference/bookacle/loaders/","title":"Loaders","text":"<p>This module defines functions for loading PDF documents and some utilities to manage loaders.</p>"},{"location":"reference/bookacle/loaders/#bookacle.loaders.LOADER_MANAGER","title":"LOADER_MANAGER  <code>module-attribute</code>","text":"<pre><code>LOADER_MANAGER = LoaderManager()\n</code></pre> <p>Default loader manager.</p>"},{"location":"reference/bookacle/loaders/#bookacle.loaders.LoaderLike","title":"LoaderLike","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol that all document loaders should follow.</p>"},{"location":"reference/bookacle/loaders/#bookacle.loaders.LoaderLike.__call__","title":"__call__","text":"<pre><code>__call__(file_path, start_page=0, end_page=None)\n</code></pre> <p>Load a PDF document.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path to the PDF file.</p> required <code>start_page</code> <code>int</code> <p>The starting (0-based) page number in the PDF to begin reading from.</p> <code>0</code> <code>end_page</code> <code>int | None</code> <p>The ending (0-based) page number to stop reading at (non-inclusive).       When <code>None</code>, all pages in the PDF are read.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Document]</code> <p>Pages in the file.</p>"},{"location":"reference/bookacle/loaders/#bookacle.loaders.LoaderManager","title":"LoaderManager","text":"<p>               Bases: <code>UserDict[str, LoaderLike]</code></p> <p>Manager to maintain registry of all document loaders.</p> <p>It behaves like a dictionary, where each document loader is registered to a name.</p> Example <pre><code>from bookacle.loaders import LoaderManager, register_loader\nfrom langchain_core.documents import Document\n\nmanager = LoaderManager()\n\n@register_loader(name=\"custom_loader\", manager=manager)\ndef doc_loader(file_path: str, start_page: int = 0, end_page: int | None = None) -&gt; list[Document]:\n    ...\n\nprint(manager[\"custom_loader\"] is doc_loader)\n</code></pre> <pre><code>True\n</code></pre>"},{"location":"reference/bookacle/loaders/#bookacle.loaders.LoaderManager.enum","title":"enum  <code>property</code>","text":"<pre><code>enum\n</code></pre> <p>Obtain the names of the document loaders as an Enum.</p> <p>Useful in the CLI for <code>--help</code>.</p>"},{"location":"reference/bookacle/loaders/#bookacle.loaders.register_loader","title":"register_loader","text":"<pre><code>register_loader(name, manager=None)\n</code></pre> <p>A decorator that registers a loader function with the loader manager.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to map the loader function to.</p> required <code>manager</code> <code>LoaderManager | None</code> <p>The manager to register the function with.      If <code>None</code>, <code>LOADER_MANAGER</code> is used.</p> <code>None</code>"},{"location":"reference/bookacle/loaders/#bookacle.loaders.pymupdf4llm_loader","title":"pymupdf4llm_loader","text":"<pre><code>pymupdf4llm_loader(file_path, start_page=0, end_page=None)\n</code></pre> <p>Document loader which uses <code>pymupdf4llm</code> to load the PDF as Markdown.</p> <p>Can be accessed using the name <code>'pymupdf4llm'</code> via the default loader manager.</p> <p>It implements the LoaderLike protocol.</p>"},{"location":"reference/bookacle/loaders/#bookacle.loaders.pymupdf_loader","title":"pymupdf_loader","text":"<pre><code>pymupdf_loader(file_path, start_page=0, end_page=None)\n</code></pre> <p>Document loader which uses <code>pymupdf</code> to load the PDF as text.</p> <p>Can be accessed using the name <code>'pymupdf'</code> via the default loader manager.</p> <p>It implements the LoaderLike protocol.</p>"},{"location":"reference/bookacle/splitters/","title":"Splitters","text":"<p>This module implements document splitters for document chunking.</p>"},{"location":"reference/bookacle/splitters/#bookacle.splitters.DocumentSplitterLike","title":"DocumentSplitterLike","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol that defines the methods that a document splitter should implement.</p>"},{"location":"reference/bookacle/splitters/#bookacle.splitters.DocumentSplitterLike.__call__","title":"__call__","text":"<pre><code>__call__(documents, chunk_size=100, chunk_overlap=0)\n</code></pre> <p>Split a list of documents into smaller chunks.</p> <p>Parameters:</p> Name Type Description Default <code>documents</code> <code>list[Document]</code> <p>The list of documents to be split.</p> required <code>chunk_size</code> <code>int</code> <p>The size of each chunk.</p> <code>100</code> <code>chunk_overlap</code> <code>int</code> <p>The overlap between consecutive chunks.</p> <code>0</code> <p>Returns:</p> Type Description <code>list[Document]</code> <p>The list of documents after splitting into chunks.</p>"},{"location":"reference/bookacle/splitters/#bookacle.splitters.HuggingFaceTextSplitter","title":"HuggingFaceTextSplitter","text":"<pre><code>HuggingFaceTextSplitter(tokenizer, separators=None)\n</code></pre> <p>Text-based document splitter which uses a HuggingFace tokenizer to calculate length when splitting.</p> <p>It uses Langchain\u2019s RecursiveCharacterTextSplitter and expects the list of documents to be in plain text.</p> <p>It implements the DocumentSplitterLike protocol.</p> <p>Attributes:</p> Name Type Description <code>tokenizer</code> <p>The HuggingFace tokenizer to use for calculating length.</p> <code>separators</code> <p>The list of separators to use for splitting the document.</p> <p>Parameters:</p> Name Type Description Default <code>tokenizer</code> <code>PreTrainedTokenizerBase</code> <p>The HuggingFace tokenizer to use for calculating length.</p> required <code>separators</code> <code>list[str] | None</code> <p>The list of separators to use.         When <code>None</code>, the default separators are used: <code>[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\"]</code>.</p> <code>None</code>"},{"location":"reference/bookacle/splitters/#bookacle.splitters.HuggingFaceMarkdownSplitter","title":"HuggingFaceMarkdownSplitter","text":"<pre><code>HuggingFaceMarkdownSplitter(tokenizer)\n</code></pre> <p>Markdown-based document splitter which uses a HuggingFace tokenizer to calculate length of chunks when splitting.</p> <p>It uses Langchain\u2019s MarkdownTextSplitter and expects the list of documents to be in Markdown.</p> <p>It implements the DocumentSplitterLike protocol.</p> <p>Attributes:</p> Name Type Description <code>tokenizer</code> <p>The HuggingFace tokenizer to use for calculating length.</p> <p>Parameters:</p> Name Type Description Default <code>tokenizer</code> <code>PreTrainedTokenizerBase</code> <p>The HuggingFace tokenizer to use to calculate length.</p> required"},{"location":"reference/bookacle/splitters/#bookacle.splitters.RaptorSplitter","title":"RaptorSplitter","text":"<pre><code>RaptorSplitter(tokenizer, *, separators=None)\n</code></pre> <p>Document splitter which implements the chunking technique as defined in the RAPTOR paper.</p> <p>It expects a tokenizer which implements the TokenizerLike protocol to calculate the length of chunks.</p> <p>For more details, see: https://github.com/parthsarthi03/raptor/blob/7da1d48a7e1d7dec61a63c9d9aae84e2dfaa5767/raptor/utils.py#L22.</p> <p>It implements the DocumentSplitterLike protocol.</p> <p>Attributes:</p> Name Type Description <code>tokenizer</code> <p>Tokenizer to use for calculating chunk lengths.</p> <code>separators</code> <p>The list of separators to use for splitting the document.</p> <p>Parameters:</p> Name Type Description Default <code>tokenizer</code> <code>TokenizerLike</code> <p>Tokenizer to use for calculating chunk lengths.</p> required <code>separators</code> <code>list[str] | None</code> <p>The list of separators to use.         When <code>None</code>, the default separators are used: <code>[\".\", \"!\", \"?\", \"\\n\"]</code>.</p> <code>None</code>"},{"location":"reference/bookacle/splitters/#bookacle.splitters.RaptorSplitter.split_single_document","title":"split_single_document","text":"<pre><code>split_single_document(document, chunk_size, chunk_overlap)\n</code></pre> <p>Split a single document into chunks.</p> <p>Parameters:</p> Name Type Description Default <code>document</code> <code>Document</code> <p>Document to split into chunks.</p> required <code>chunk_size</code> <code>int</code> <p>Maximum size of each chunk.</p> required <code>chunk_overlap</code> <code>int</code> <p>Overlap between each chunk.</p> required"},{"location":"reference/bookacle/tokenizer/","title":"Tokenizer","text":""},{"location":"reference/bookacle/tokenizer/#bookacle.tokenizer.TokenizerLike","title":"TokenizerLike","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol that all tokenizers should follow.</p>"},{"location":"reference/bookacle/tokenizer/#bookacle.tokenizer.TokenizerLike.encode","title":"encode","text":"<pre><code>encode(*args, **kwargs)\n</code></pre> <p>Tokenize the input text into a list of integers.</p> <p>Returns:</p> Type Description <code>list[int]</code> <p>Tokenized input.</p>"},{"location":"reference/bookacle/conf/","title":"Conf","text":""},{"location":"reference/bookacle/conf/config/","title":"Config","text":""},{"location":"reference/bookacle/models/","title":"Models","text":""},{"location":"reference/bookacle/models/embedding/","title":"Embedding","text":"<p>This module defines protocols and concrete implementations for embedding models used for text representation.</p>"},{"location":"reference/bookacle/models/embedding/#bookacle.models.embedding.EmbeddingModelLike","title":"EmbeddingModelLike","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol that defines the methods and attributes that an embedding model should implement.</p>"},{"location":"reference/bookacle/models/embedding/#bookacle.models.embedding.EmbeddingModelLike.tokenizer","title":"tokenizer  <code>property</code>","text":"<pre><code>tokenizer\n</code></pre> <p>Returns:</p> Type Description <code>TokenizerLike</code> <p>The tokenizer used by the model.</p>"},{"location":"reference/bookacle/models/embedding/#bookacle.models.embedding.EmbeddingModelLike.model_max_length","title":"model_max_length  <code>property</code>","text":"<pre><code>model_max_length\n</code></pre> <p>Returns:</p> Type Description <code>int</code> <p>The maximum length of the input that the model can accept.</p>"},{"location":"reference/bookacle/models/embedding/#bookacle.models.embedding.EmbeddingModelLike.embed","title":"embed","text":"<pre><code>embed(text)\n</code></pre> <p>Embed the input text or list of texts.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str | list[str]</code> <p>The input text or list of input texts to embed.</p> required <p>Returns:</p> Type Description <code>list[float] | list[list[float]]</code> <p>The embeddings of the input text or list of texts.</p>"},{"location":"reference/bookacle/models/embedding/#bookacle.models.embedding.SentenceTransformerEmbeddingModel","title":"SentenceTransformerEmbeddingModel","text":"<pre><code>SentenceTransformerEmbeddingModel(\n    model_name, *, use_gpu=False\n)\n</code></pre> <p>An embedding model that uses the SentenceTransformer library.</p> <p>It implements the EmbeddingModelLike protocol.</p> <p>Attributes:</p> Name Type Description <code>model_name</code> <code>str</code> <p>The name of the model to use.</p> <code>use_gpu</code> <code>bool</code> <p>Whether to use the GPU for inference.</p> <code>model</code> <code>SentenceTransformer</code> <p>The SentenceTransformer model.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>The name of the model to use.</p> required <code>use_gpu</code> <code>bool</code> <p>Whether to use the GPU for inference.</p> <code>False</code>"},{"location":"reference/bookacle/models/embedding/#bookacle.models.embedding.SentenceTransformerEmbeddingModel.tokenizer","title":"tokenizer  <code>property</code>","text":"<pre><code>tokenizer\n</code></pre> <p>Returns:</p> Type Description <code>PreTrainedTokenizerBase</code> <p>The tokenizer used by the underlying model.</p>"},{"location":"reference/bookacle/models/message/","title":"Message","text":"<p>This module defines data structures for representing messages exchanged in a conversation with a language model (LLM).</p>"},{"location":"reference/bookacle/models/message/#bookacle.models.message.Message","title":"Message","text":"<p>               Bases: <code>TypedDict</code></p> <p>A TypedDict that represents a message in a conversation with an LLM.</p> <p>Attributes:</p> Name Type Description <code>role</code> <code>Literal['user', 'assistant', 'system', 'tool']</code> <p>The role of the message sender.</p> <code>content</code> <code>str</code> <p>The content of the message.</p>"},{"location":"reference/bookacle/models/qa/","title":"Qa","text":"<p>This module defines a protocol and an implementation for a Question-Answering (QA) model that processes questions and returns answers with or without streaming capabilities.</p>"},{"location":"reference/bookacle/models/qa/#bookacle.models.qa.QAModelLike","title":"QAModelLike","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol that defines the methods that a QA model should implement.</p>"},{"location":"reference/bookacle/models/qa/#bookacle.models.qa.QAModelLike.answer","title":"answer","text":"<pre><code>answer(\n    question,\n    context,\n    history=None,\n    *args,\n    stream=False,\n    **kwargs\n)\n</code></pre> <p>Answer a question given a context and chat history with or without streaming.</p> <p>Parameters:</p> Name Type Description Default <code>question</code> <code>str</code> <p>The question to answer.</p> required <code>context</code> <code>str</code> <p>The context for the question.</p> required <code>history</code> <code>list[Message] | None</code> <p>The chat history.</p> <code>None</code> <code>stream</code> <code>bool</code> <p>Whether to stream the AI response.</p> <code>False</code> <p>Returns:</p> Type Description <code>Message | Iterator[Message]</code> <p>A single message from the QA model or a stream of messages.</p>"},{"location":"reference/bookacle/models/qa/#bookacle.models.qa.OllamaQAModel","title":"OllamaQAModel","text":"<pre><code>OllamaQAModel(model_name)\n</code></pre> <p>A QA model that uses the Ollama library.</p> <p>It implements the QAModelLike protocol.</p> <p>Attributes:</p> Name Type Description <code>model_name</code> <code>str</code> <p>The name of the model to use.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>The name of the model to use.</p> required"},{"location":"reference/bookacle/models/qa/#bookacle.models.qa.OllamaQAModel.answer","title":"answer","text":"<pre><code>answer(\n    question,\n    context,\n    history=None,\n    *args,\n    stream=True,\n    **kwargs\n)\n</code></pre> <p>Answer a question given a context and chat history with or without streaming.</p> <p>The question and the context are combined into a single message for the QA model, using the following template:</p> <pre><code>CONTEXT:\n&lt;context&gt;\n\nQUERY: &lt;question&gt;\n</code></pre> <p>After combining the question and context, the message is appended to the history (if any) and sent to the QA model.</p> <p>A system prompt can be provided by adding it as the first message in the history.</p>"},{"location":"reference/bookacle/models/summarization/","title":"Summarization","text":"<p>This module defines protocols and concrete implementations for summarization models used for summarizing texts in intermediate RAPTOR tree layers.</p>"},{"location":"reference/bookacle/models/summarization/#bookacle.models.summarization.SummarizationModelLike","title":"SummarizationModelLike","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol that defines the methods and attributes that a summarization model should implement.</p>"},{"location":"reference/bookacle/models/summarization/#bookacle.models.summarization.SummarizationModelLike.tokenizer","title":"tokenizer  <code>property</code>","text":"<pre><code>tokenizer\n</code></pre> <p>Returns:</p> Type Description <code>TokenizerLike</code> <p>The tokenizer used by the model.</p>"},{"location":"reference/bookacle/models/summarization/#bookacle.models.summarization.SummarizationModelLike.summarize","title":"summarize","text":"<pre><code>summarize(text)\n</code></pre> <p>Summarize the input text or list of texts.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str | list[str]</code> <p>The input text or list of input texts to summarize.</p> required <p>Returns:</p> Type Description <code>str | list[str]</code> <p>The summary of the input text or list of texts.</p>"},{"location":"reference/bookacle/models/summarization/#bookacle.models.summarization.HuggingFaceSummarizationModel","title":"HuggingFaceSummarizationModel","text":"<pre><code>HuggingFaceSummarizationModel(\n    model_name, summarization_length=100, *, use_gpu=False\n)\n</code></pre> <p>A class that uses a Hugging Face model for summarization.</p> <p>It implements the SummarizationModelLike protocol.</p> <p>Attributes:</p> Name Type Description <code>model_name</code> <code>str</code> <p>The name of the Hugging Face model to use.</p> <code>summarization_length</code> <code>int</code> <p>The maximum length of the summary.</p> <code>use_gpu</code> <code>bool</code> <p>Whether to use the GPU for inference.</p> <code>model</code> <code>AutoModelForSeq2SeqLM</code> <p>The Hugging Face model for summarization.</p> <code>pipeline</code> <code>Pipeline</code> <p>The Hugging Face pipeline for summarization.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>The name of the Hugging Face model to use.</p> required <code>summarization_length</code> <code>int</code> <p>The maximum length of the summary.</p> <code>100</code> <code>use_gpu</code> <code>bool</code> <p>Whether to use the GPU for inference.</p> <code>False</code>"},{"location":"reference/bookacle/models/summarization/#bookacle.models.summarization.HuggingFaceSummarizationModel.tokenizer","title":"tokenizer  <code>property</code>","text":"<pre><code>tokenizer\n</code></pre> <p>Returns:</p> Type Description <code>PreTrainedTokenizerBase</code> <p>The Hugging Face tokenizer used by the underlying model.</p>"},{"location":"reference/bookacle/models/summarization/#bookacle.models.summarization.HuggingFaceLLMSummarizationModel","title":"HuggingFaceLLMSummarizationModel","text":"<pre><code>HuggingFaceLLMSummarizationModel(\n    model_name,\n    summarization_length=100,\n    *,\n    system_prompt=\"\",\n    use_gpu=False\n)\n</code></pre> <p>A class that uses a Hugging Face LLM for summarization.</p> <p>It implements the SummarizationModelLike protocol.</p> <p>Attributes:</p> Name Type Description <code>model_name</code> <code>str</code> <p>The name of the Hugging Face LLM to use.</p> <code>summarization_length</code> <code>int</code> <p>The maximum length of the summary.</p> <code>system_prompt</code> <code>str</code> <p>The system prompt passed to the LLM for summarization.</p> <code>use_gpu</code> <code>bool</code> <p>Whether to use the GPU for inference.</p> <code>model</code> <code>AutoModelForCausalLM</code> <p>The Hugging Face LLM for summarization.</p> <code>pipeline</code> <code>Pipeline</code> <p>The Hugging Face pipeline for summarization.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>The name of the Hugging Face model to use.</p> required <code>summarization_length</code> <code>int</code> <p>The maximum length of the summary.</p> <code>100</code> <code>system_prompt</code> <code>str</code> <p>The system prompt to pass to the LLM for summarization.</p> <code>''</code> <code>use_gpu</code> <code>bool</code> <p>Whether to use the GPU for inference.</p> <code>False</code>"},{"location":"reference/bookacle/models/summarization/#bookacle.models.summarization.HuggingFaceLLMSummarizationModel.tokenizer","title":"tokenizer  <code>property</code>","text":"<pre><code>tokenizer\n</code></pre> <p>Returns:</p> Type Description <code>PreTrainedTokenizerBase</code> <p>The Hugging Face tokenizer used by the underlying model.</p>"},{"location":"reference/bookacle/models/summarization/#bookacle.models.summarization.HuggingFaceLLMSummarizationModel.format_as_chat_message","title":"format_as_chat_message","text":"<pre><code>format_as_chat_message(text)\n</code></pre> <p>Format the input text or list of texts as chat messages.</p> <p>A chat message is a dictionary with the keys \u2018role\u2019 and \u2018content\u2019.</p> If the input is a list of texts <ul> <li>If the system prompt is provided, a list of lists containing the system prompt and user message is returned.</li> <li>If the system prompt is not provided, a list of lists containing the user messages is returned.</li> </ul> If the input is a single text <ul> <li>If the system prompt is provided, a list containing the system prompt and user message is returned.</li> <li>If the system prompt is not provided, a list containing only the user message is returned.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str | list[str]</code> <p>The input text or list of texts to format.</p> required <p>Returns:</p> Type Description <code>list[Message] | list[list[Message]]</code> <p>The formatted chat messages.</p> Example Single Text<pre><code>from bookacle.models.summarization import HuggingFaceLLMSummarizationModel\nmodel = HuggingFaceLLMSummarizationModel(model_name=\"Qwen/Qwen2-0.5B-Instruct\")\ntext = \"This is a test\"\nprint(model.format_as_chat_message(text))\n</code></pre> <pre><code>[{'role': 'user', 'content': 'Summarize the following in not more than 100 words:\\nThis is a test'}]\n</code></pre> Mutliple Texts<pre><code>from bookacle.models.summarization import HuggingFaceLLMSummarizationModel\nmodel = HuggingFaceLLMSummarizationModel(model_name=\"Qwen/Qwen2-0.5B-Instruct\")\ntext = [\"This is a test\", \"This is another test\"]\nprint(model.format_as_chat_message(text))\n</code></pre> <pre><code>[[{'role': 'user', 'content': 'Summarize the following in not more than 100 words:\\nThis is a test'}], [{'role': 'user', 'content': 'Summarize the following in not more than 100 words:\\nThis is another test'}]]\n</code></pre>"},{"location":"reference/bookacle/models/summarization/#bookacle.models.summarization.HuggingFaceLLMSummarizationModel.summarize","title":"summarize","text":"<pre><code>summarize(text)\n</code></pre> <p>Summarize the input text or list of texts.</p> <p>The input is first formatted into chat messages using format_as_chat_message() and then passed to the underlying LLM for summarization.</p> <p>Each input text is passed to the LLM with the following format:</p> <pre><code>\"Summarize the following in not more than {summarization_length} words:\\n{text}\"\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str | list[str]</code> <p>The input text or list of texts to summarize.</p> required <p>Returns:</p> Type Description <code>str | list[str]</code> <p>The summary of the input text or list of texts.</p>"},{"location":"reference/bookacle/tree/","title":"Tree","text":""},{"location":"reference/bookacle/tree/builder/","title":"Builder","text":""},{"location":"reference/bookacle/tree/builder/#bookacle.tree.builder.TreeBuilderLike","title":"TreeBuilderLike","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol that defines the interface for a RAPTOR tree builder.</p>"},{"location":"reference/bookacle/tree/builder/#bookacle.tree.builder.TreeBuilderLike.build_from_documents","title":"build_from_documents","text":"<pre><code>build_from_documents(\n    documents,\n    chunk_size=None,\n    chunk_overlap=None,\n    *args,\n    **kwargs\n)\n</code></pre> <p>Build a tree from a list of documents.</p> <p>Parameters:</p> Name Type Description Default <code>documents</code> <code>list[Document]</code> <p>A list of documents to build the tree from.</p> required <code>chunk_size</code> <code>int | None</code> <p>The size of the chunks to split the documents into.</p> <code>None</code> <code>chunk_overlap</code> <code>int | None</code> <p>The overlap between the chunks.</p> <code>None</code> <code>*args</code> <p>Additional positional arguments.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tree</code> <p>A tree built from the documents.</p>"},{"location":"reference/bookacle/tree/builder/#bookacle.tree.builder.ClusterTreeBuilder","title":"ClusterTreeBuilder","text":"<pre><code>ClusterTreeBuilder(config)\n</code></pre> <p>A RAPTOR tree builder that clusters nodes at each subsequent tree layer to build the tree.</p> <p>It implements the TreeBuilderLike protocol.</p> <p>Attributes:</p> Name Type Description <code>config</code> <code>RaptorTreeConfig</code> <p>The configuration for the tree builder.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>RaptorTreeConfig</code> <p>The configuration for the tree builder.</p> required"},{"location":"reference/bookacle/tree/builder/#bookacle.tree.builder.ClusterTreeBuilder.create_leaf_nodes","title":"create_leaf_nodes","text":"<pre><code>create_leaf_nodes(chunks, embeddings)\n</code></pre> <p>Create leaf nodes from the given chunks.</p> <p>Parameters:</p> Name Type Description Default <code>chunks</code> <code>list[Document]</code> <p>The chunks to create the leaf nodes from.</p> required <code>embeddings</code> <code>list[list[float]]</code> <p>The embeddings of the chunks.</p> required <p>Returns:</p> Type Description <code>dict[int, Node]</code> <p>A mapping of the global index to the created leaf nodes.</p>"},{"location":"reference/bookacle/tree/builder/#bookacle.tree.builder.ClusterTreeBuilder.create_next_tree_level","title":"create_next_tree_level","text":"<pre><code>create_next_tree_level(clusters, first_node_index, layer)\n</code></pre> <p>Create the next tree level from the given clusters.</p> For each cluster <ul> <li>The texts of the nodes in the cluster are concatenated.</li> <li>The concatenated text is summarized.</li> <li>The summarized text is embedded.</li> <li>A Node is created with the summarized text, embeddings, and the indices of the children nodes.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>clusters</code> <code>list[list[Node]]</code> <p>The clusters to create the next tree level from.</p> required <code>first_node_index</code> <code>int</code> <p>The global index of the first node in the new layer.</p> required <code>layer</code> <code>int</code> <p>The layer of the tree the clusters belong to.</p> required <p>Returns:</p> Type Description <code>dict[int, Node]</code> <p>A mapping of the global indices to the created nodes.</p>"},{"location":"reference/bookacle/tree/builder/#bookacle.tree.builder.ClusterTreeBuilder.construct_tree","title":"construct_tree","text":"<pre><code>construct_tree(chunks, embeddings, reduction_dimension=10)\n</code></pre> <p>Construct a RAPTOR tree from the given chunks and embeddings.</p> <p>The tree is built in a bottom-up manner, starting from the leaf nodes and going up to the root nodes.</p> To build the tree <ul> <li>The leaf nodes are created from the chunks and embeddings.</li> <li>The leaf nodes are clustered to create the next tree level using create_next_tree_level().</li> <li>The process is repeated until the maximum number of layers is reached or the number of nodes in the next level is less than the reduction dimension.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>chunks</code> <code>list[Document]</code> <p>The chunks to construct the tree from.</p> required <code>embeddings</code> <code>list[list[float]]</code> <p>The embeddings of the chunks.</p> required <code>reduction_dimension</code> <code>int</code> <p>The dimension to reduce the embeddings to before clustering.</p> <code>10</code> <p>Returns:</p> Type Description <code>Tree</code> <p>A RAPTOR tree constructed from the chunks and embeddings.</p>"},{"location":"reference/bookacle/tree/builder/#bookacle.tree.builder.ClusterTreeBuilder.build_from_documents","title":"build_from_documents","text":"<pre><code>build_from_documents(\n    documents, chunk_size=None, chunk_overlap=None\n)\n</code></pre> <p>Build a RAPTOR tree from the given documents.</p> <p>Each document is split into chunks and each chunk is embedded. These are then passed to the construct_tree() method to build the tree.</p> <p>Parameters:</p> Name Type Description Default <code>documents</code> <code>list[Document]</code> <p>The documents to build the tree from.</p> required <code>chunk_size</code> <code>int | None</code> <p>The size of the chunks to split the documents into.         When <code>None</code>, it defaults to the maximum length supported by the embedding model.</p> <code>None</code> <code>chunk_overlap</code> <code>int | None</code> <p>The overlap between the chunks. When <code>None</code>, it defaults to half the chunk size.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tree</code> <p>A RAPTOR tree built from the documents.</p>"},{"location":"reference/bookacle/tree/clustering/","title":"Clustering","text":""},{"location":"reference/bookacle/tree/clustering/#bookacle.tree.clustering.ClusteringBackendLike","title":"ClusteringBackendLike","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol that defines the interface a clustering backend should implement.</p>"},{"location":"reference/bookacle/tree/clustering/#bookacle.tree.clustering.ClusteringBackendLike.cluster","title":"cluster","text":"<pre><code>cluster(embeddings, *args, **kwargs)\n</code></pre> <p>Cluster the embeddings.</p> <p>Parameters:</p> Name Type Description Default <code>embeddings</code> <code>NDArray[float64]</code> <p>The embeddings to cluster.</p> required <code>*args</code> <p>Additional arguments to pass to the clustering function.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the clustering function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tuple[dict[int, list[int]], dict[int, list[int]]]</code> <p>A tuple containing the mapping of embeddings to clusters and the mapping of clusters to embeddings.</p>"},{"location":"reference/bookacle/tree/clustering/#bookacle.tree.clustering.ClusteringFunctionLike","title":"ClusteringFunctionLike","text":"<p>               Bases: <code>Protocol</code></p> <p>A protocol that defines the interface a clustering function should implement.</p>"},{"location":"reference/bookacle/tree/clustering/#bookacle.tree.clustering.ClusteringFunctionLike.__call__","title":"__call__","text":"<pre><code>__call__(\n    nodes,\n    tokenizer,\n    clustering_backend=None,\n    max_length_in_cluster=3500,\n    reduction_dimension=10,\n    *args,\n    **kwargs\n)\n</code></pre> <p>Cluster nodes using the given clustering backend.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list[Node]</code> <p>The nodes to cluster.</p> required <code>tokenizer</code> <code>TokenizerLike</code> <p>The tokenizer to use to calculate the total length of text in each cluster.</p> required <code>clustering_backend</code> <code>ClusteringBackendLike | None</code> <p>The clustering backend to use.</p> <code>None</code> <code>max_length_in_cluster</code> <code>int</code> <p>The maximum length of text in a cluster.</p> <code>3500</code> <code>reduction_dimension</code> <code>int</code> <p>The dimension to reduce the embeddings to before clustering.</p> <code>10</code> <code>*args</code> <p>Additional arguments to pass to the clustering function.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the clustering function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[list[Node]]</code> <p>The clustered nodes.</p>"},{"location":"reference/bookacle/tree/clustering/#bookacle.tree.clustering.GMMClusteringBackend","title":"GMMClusteringBackend","text":"<pre><code>GMMClusteringBackend(\n    reduction_dim,\n    max_clusters=50,\n    random_state=42,\n    n_neighbors_global=None,\n    n_neighbors_local=10,\n    n_clusters_global=None,\n    n_clusters_local=None,\n    umap_metric=\"cosine\",\n    umap_low_memory=True,\n)\n</code></pre> <p>A Gaussian Mixture Model (GMM) clustering backend.</p> <p>It implements the ClusteringBackendLike protocol.</p> <p>Attributes:</p> Name Type Description <code>reduction_dim</code> <code>int</code> <p>The dimension to reduce the embeddings to before clustering.</p> <code>max_clusters</code> <code>int</code> <p>The maximum number of clusters to use.</p> <code>random_state</code> <code>int</code> <p>Random state for reproducibility.</p> <code>n_neighbors_global</code> <code>int | None</code> <p>The number of neighbors to use for global clustering.</p> <code>n_neighbors_local</code> <code>int | None</code> <p>The number of neighbors to use for local clustering.</p> <code>n_clusters_global</code> <code>int | None</code> <p>The number of clusters to use for global clustering.</p> <code>n_clusters_local</code> <code>int | None</code> <p>The number of clusters to use for local clustering.</p> <code>umap_metric</code> <code>str</code> <p>The metric to use for UMAP.</p> <code>umap_low_memory</code> <code>bool</code> <p>Whether to use low memory mode for UMAP.</p> <p>Parameters:</p> Name Type Description Default <code>reduction_dim</code> <code>int</code> <p>The dimension to reduce the embeddings to before clustering.</p> required <code>max_clusters</code> <code>int</code> <p>The maximum number of clusters to use.</p> <code>50</code> <code>random_state</code> <code>int</code> <p>Random state for reproducibility.</p> <code>42</code> <code>n_neighbors_global</code> <code>int | None</code> <p>The number of neighbors to use for global clustering.                 When <code>None</code>, it is calculated using Bayesian Information Criterion (BIC).</p> <code>None</code> <code>n_neighbors_local</code> <code>int</code> <p>The number of neighbors to use for local clustering.                 When <code>None</code>, it is calculated using Bayesian Information Criterion (BIC).</p> <code>10</code> <code>n_clusters_global</code> <code>int | None</code> <p>The number of clusters to use for global clustering.</p> <code>None</code> <code>n_clusters_local</code> <code>int | None</code> <p>The number of clusters to use for local clustering.</p> <code>None</code> <code>umap_metric</code> <code>str</code> <p>The metric to use for UMAP.</p> <code>'cosine'</code> <code>umap_low_memory</code> <code>bool</code> <p>Whether to use low memory mode for UMAP.</p> <code>True</code>"},{"location":"reference/bookacle/tree/clustering/#bookacle.tree.clustering.GMMClusteringBackend.get_optimal_clusters_count","title":"get_optimal_clusters_count","text":"<pre><code>get_optimal_clusters_count(embeddings)\n</code></pre> <p>Get the optimal number of clusters using the Bayesian Information Criterion (BIC).</p> <p>The method fits multiple Gaussian Mixture Models (GMM) to the embeddings and calculates the BIC for each. The number of clusters with the lowest BIC score is selected as the optimal number.</p> <p>Parameters:</p> Name Type Description Default <code>embeddings</code> <code>NDArray[float64]</code> <p>The embeddings to cluster.</p> required <p>Returns:</p> Type Description <code>int</code> <p>The optimal number of clusters.</p>"},{"location":"reference/bookacle/tree/clustering/#bookacle.tree.clustering.GMMClusteringBackend.get_clusters","title":"get_clusters","text":"<pre><code>get_clusters(embeddings, n_clusters)\n</code></pre> <p>Fit the GMM model to embeddings and return cluster assignments.</p> <p>Parameters:</p> Name Type Description Default <code>embeddings</code> <code>NDArray[float64]</code> <p>The embeddings to cluster.</p> required <code>n_clusters</code> <code>int</code> <p>The number of clusters to use.</p> required <p>Returns:</p> Type Description <code>NDArray[int64]</code> <p>The cluster assignments.</p>"},{"location":"reference/bookacle/tree/clustering/#bookacle.tree.clustering.GMMClusteringBackend.reduce_and_cluster_embeddings","title":"reduce_and_cluster_embeddings","text":"<pre><code>reduce_and_cluster_embeddings(\n    embeddings, n_components, n_neighbors, n_clusters=None\n)\n</code></pre> <p>Reduce the dimensionality of the embeddings using UMAP and cluster them using GMM.</p> <p>It uses umap_reduce_embeddings() to reduce the dimensionality of the embeddings and get_clusters() to cluster them.</p> <p>Generally speaking, this method should be used instead of calling get_clusters() directly.</p> <p>Parameters:</p> Name Type Description Default <code>embeddings</code> <code>NDArray[float64]</code> <p>The embeddings to cluster.</p> required <code>n_components</code> <code>int</code> <p>The number of components in the reduced space.</p> required <code>n_neighbors</code> <code>int</code> <p>The number of neighbors to use for UMAP.</p> required <code>n_clusters</code> <code>int | None</code> <p>The number of clusters to use. When <code>None</code>, the optimal number of clusters is         calculated using         get_optimal_clusters_count().</p> <code>None</code> <p>Returns:</p> Type Description <code>NDArray[int64]</code> <p>The cluster assignments.</p>"},{"location":"reference/bookacle/tree/clustering/#bookacle.tree.clustering.GMMClusteringBackend.cluster_locally","title":"cluster_locally","text":"<pre><code>cluster_locally(\n    embeddings,\n    global_cluster_indices,\n    n_clusters=None,\n    n_neighbors=10,\n)\n</code></pre> <p>Cluster the embeddings of a global cluster locally. In other words, create new clusters from the embeddings of a global cluster.</p> <p>If the number of embeddings in the global cluster is less than or equal to reduction_dim, the global cluster is returned as is in a singleton list.</p> <p>Parameters:</p> Name Type Description Default <code>embeddings</code> <code>NDArray[float64]</code> <p>The overall embeddings.</p> required <code>global_cluster_indices</code> <code>NDArray[int64]</code> <p>The indices of the embeddings belonging to the global cluster.</p> required <code>n_clusters</code> <code>int | None</code> <p>The number of clusters to output.         When <code>None</code>, the optimal number of clusters is calculated using BIC.</p> <code>None</code> <code>n_neighbors</code> <code>int</code> <p>The number of neighbors to use for UMAP.</p> <code>10</code> <p>Returns:</p> Type Description <code>list[NDArray[int64]]</code> <p>The local clusters.</p> <p>Examples:</p> <pre><code>import numpy as np\nfrom bookacle.tree.clustering import GMMClusteringBackend\n\nbackend = GMMClusteringBackend(reduction_dim=10)\nembeddings = np.random.rand(100, 768)\nindices = np.random.choice(100, 30)\nclusters = backend.cluster_locally(\n    embeddings=embeddings,\n    global_cluster_indices=indices,\n    n_clusters=5,\n    n_neighbors=10,\n)\nprint(clusters)\n</code></pre> <pre><code>[array([66, 33, 40, 14, 40]), array([38, 88, 64, 97, 46, 53, 25]), array([ 6, 79, 61, 10, 45, 29, 82, 45, 85]), array([70, 68, 73, 18, 36]), array([11, 62,  1, 39])]\n</code></pre>"},{"location":"reference/bookacle/tree/clustering/#bookacle.tree.clustering.GMMClusteringBackend.cluster","title":"cluster","text":"<pre><code>cluster(embeddings)\n</code></pre> <p>Cluster the embeddings.</p> The clustering is done as follows <ul> <li>Global clustering: The embeddings are reduced and clustered globally.                      That is, the entire set of embeddings is clustered.</li> <li>Local clustering: The embeddings of each global cluster are reduced and clustered.</li> <li>At the end, all local clusters are aggregated into a single result.</li> </ul> <p>Parallel from <code>joblib</code> is used to parallelize the clustering of each global cluster.</p> <p>Parameters:</p> Name Type Description Default <code>embeddings</code> <code>NDArray[float64]</code> <p>The embeddings to cluster.</p> required <p>Returns:</p> Type Description <code>dict[int, list[int]]</code> <p>A mapping of embeddings to clusters</p> <code>dict[int, list[int]]</code> <p>A mapping of clusters to embeddings.</p> <p>Examples:</p> <p><pre><code>import numpy as np\nfrom bookacle.tree.clustering import GMMClusteringBackend\n\nbackend = GMMClusteringBackend(reduction_dim=10, n_clusters_global=3)\nembeddings = np.random.rand(10, 768)\nemb_to_clusters, clusters_to_emb = backend.cluster(embeddings=embeddings)\nprint(clusters_to_emb)\n</code></pre> <pre><code>defaultdict(&lt;class 'list'&gt;, {0: [0, 3, 5, 6], 1: [2, 8, 9], 2: [1, 4, 7]})\n</code></pre></p>"},{"location":"reference/bookacle/tree/clustering/#bookacle.tree.clustering.umap_reduce_embeddings","title":"umap_reduce_embeddings","text":"<pre><code>umap_reduce_embeddings(\n    embeddings,\n    n_components,\n    neighbors=10,\n    metric=\"cosine\",\n    low_memory=True,\n)\n</code></pre> <p>Reduce the dimensionality of the embeddings using UMAP.</p> <p>Parameters:</p> Name Type Description Default <code>embeddings</code> <code>NDArray[float64]</code> <p>The embeddings to reduce.</p> required <code>n_components</code> <code>int</code> <p>The number of components in the reduced space.</p> required <code>neighbors</code> <code>int</code> <p>The number of neighbors to use for UMAP.</p> <code>10</code> <code>metric</code> <code>str</code> <p>The metric to use for UMAP.</p> <code>'cosine'</code> <code>low_memory</code> <code>bool</code> <p>Whether to use low memory mode for UMAP.</p> <code>True</code> <p>Returns:</p> Type Description <code>NDArray[float64]</code> <p>The reduced embeddings.</p>"},{"location":"reference/bookacle/tree/clustering/#bookacle.tree.clustering.raptor_clustering","title":"raptor_clustering","text":"<pre><code>raptor_clustering(\n    nodes,\n    tokenizer,\n    clustering_backend=None,\n    max_length_in_cluster=3500,\n    reduction_dimension=10,\n)\n</code></pre> <p>Cluster nodes using RAPTOR clustering.</p> <p>It implements the ClusteringFunctionLike protocol.</p> To cluster the nodes <ul> <li>The nodes are clustered using the given clustering backend.</li> <li>For each cluster:<ul> <li>If the cluster has only one node or the total length of text in the cluster is less than the maximum length, the cluster is kept as is.</li> <li>Otherwise, the cluster is recursively clustered.</li> </ul> </li> </ul>"},{"location":"reference/bookacle/tree/config/","title":"Config","text":""},{"location":"reference/bookacle/tree/retriever/","title":"Retriever","text":""},{"location":"reference/bookacle/tree/structures/","title":"Structures","text":""},{"location":"reference/bookacle/tree/structures/#bookacle.tree.structures.Node","title":"Node  <code>dataclass</code>","text":"<pre><code>Node(\n    text,\n    index,\n    children,\n    embeddings,\n    metadata=None,\n    layer=0,\n)\n</code></pre> <p>A node in the RAPTOR tree.</p> <p>Attributes:</p> Name Type Description <code>text</code> <code>str</code> <p>The text of the node.</p> <code>index</code> <code>int</code> <p>The global index of the node in the tree.</p> <code>children</code> <code>set[int]</code> <p>The global indices of the children nodes.</p> <code>embeddings</code> <code>list[float]</code> <p>Embeddings of the node\u2019s text.</p> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Metadata about the node\u2019s text.</p> <code>layer</code> <code>int</code> <p>Tree layer the node belongs to.</p>"},{"location":"reference/bookacle/tree/structures/#bookacle.tree.structures.Node.num_children","title":"num_children  <code>property</code>","text":"<pre><code>num_children\n</code></pre> <p>Returns:</p> Type Description <code>int</code> <p>Number of children nodes.</p>"},{"location":"reference/bookacle/tree/structures/#bookacle.tree.structures.Node.from_text","title":"from_text  <code>classmethod</code>","text":"<pre><code>from_text(\n    index,\n    text,\n    embedding_model,\n    children_indices=None,\n    metadata=None,\n    layer=0,\n)\n</code></pre> <p>Create a node from text by embedding it using the given embedding model.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>The global index of the node in the tree.</p> required <code>text</code> <code>str</code> <p>The text of the node.</p> required <code>embedding_model</code> <code>EmbeddingModelLike</code> <p>The embedding model to use for embedding the text.</p> required <code>children_indices</code> <code>set[int] | None</code> <p>The global indices of the children nodes.</p> <code>None</code> <code>metadata</code> <code>dict[str, str] | None</code> <p>Metadata about the node\u2019s text.</p> <code>None</code> <code>layer</code> <code>int</code> <p>Tree layer the node belongs to.</p> <code>0</code> <p>Returns:</p> Type Description <code>Node</code> <p>A node created from the text.</p>"},{"location":"reference/bookacle/tree/structures/#bookacle.tree.structures.Node.from_children","title":"from_children  <code>classmethod</code>","text":"<pre><code>from_children(\n    children,\n    embedding_model,\n    summarization_model,\n    index,\n    layer=0,\n)\n</code></pre> <p>Create a node from a list of children nodes by summarizing their texts.</p> <p>The text of the children nodes is concatenated using concatenate_node_texts() and passed to the summarization model to generate a summary.</p> <p>Parameters:</p> Name Type Description Default <code>children</code> <code>list[Node]</code> <p>A list of children nodes.</p> required <code>embedding_model</code> <code>EmbeddingModelLike</code> <p>The embedding model to use for embedding the summarized text.</p> required <code>summarization_model</code> <code>SummarizationModelLike</code> <p>The summarization model to use for summarizing                  the text of the children nodes.</p> required <code>index</code> <code>int</code> <p>The global index of the node in the tree.</p> required <code>layer</code> <code>int</code> <p>Tree layer the node belongs to.</p> <code>0</code> <p>Returns:</p> Type Description <code>Node</code> <p>A node created from the children nodes.</p>"},{"location":"reference/bookacle/tree/structures/#bookacle.tree.structures.Tree","title":"Tree  <code>dataclass</code>","text":"<pre><code>Tree(\n    all_nodes,\n    root_nodes,\n    leaf_nodes,\n    num_layers,\n    layer_to_nodes,\n)\n</code></pre> <p>A RAPTOR tree.</p> <p>Attributes:</p> Name Type Description <code>all_nodes</code> <code>dict[int, Node]</code> <p>All nodes in the tree, mapped to their global indices.</p> <code>root_nodes</code> <code>dict[int, Node]</code> <p>Root nodes in the tree, mapped to their global indices.</p> <code>leaf_nodes</code> <code>dict[int, Node]</code> <p>Leaf nodes in the tree, mapped to their global indices.</p> <code>num_layers</code> <code>int</code> <p>Number of layers in the tree.</p> <code>layer_to_nodes</code> <code>dict[int, list[Node]]</code> <p>Nodes in a layer, mapped to their layer index.</p>"},{"location":"reference/bookacle/tree/structures/#bookacle.tree.structures.Tree.num_nodes","title":"num_nodes  <code>property</code>","text":"<pre><code>num_nodes\n</code></pre> <p>Returns:</p> Type Description <code>int</code> <p>The number of nodes in the tree.</p>"},{"location":"reference/bookacle/tree/structures/#bookacle.tree.structures.Tree.top_layer","title":"top_layer  <code>property</code>","text":"<pre><code>top_layer\n</code></pre> <p>Returns:</p> Type Description <code>int</code> <p>Index of the root layer of the tree.</p>"},{"location":"reference/bookacle/tree/structures/#bookacle.tree.structures.Tree.tolist","title":"tolist","text":"<pre><code>tolist()\n</code></pre> <p>Returns:</p> Type Description <code>list[Node]</code> <p>List of all nodes in the tree.</p>"},{"location":"reference/bookacle/tree/structures/#bookacle.tree.structures.Tree.get_node","title":"get_node","text":"<pre><code>get_node(index)\n</code></pre> <p>Fetch a node in the tree by its global index.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>The global index of the node to fetch.</p> required <p>Returns:</p> Type Description <code>Node</code> <p>The node with the given global index.</p>"},{"location":"reference/bookacle/tree/structures/#bookacle.tree.structures.Tree.fetch_layer","title":"fetch_layer","text":"<pre><code>fetch_layer(layer)\n</code></pre> <p>Fetch all nodes in a layer of the tree.</p> <p>Parameters:</p> Name Type Description Default <code>layer</code> <code>int</code> <p>The layer index to fetch nodes from.</p> required <p>Returns:</p> Type Description <code>list[Node]</code> <p>List of nodes in the given layer.</p>"},{"location":"reference/bookacle/tree/structures/#bookacle.tree.structures.Tree.fetch_node_layer","title":"fetch_node_layer","text":"<pre><code>fetch_node_layer(node_idx)\n</code></pre> <p>Fetch the index of the layer a node belongs to in the tree.</p> <p>Parameters:</p> Name Type Description Default <code>node_idx</code> <code>int</code> <p>The global index of the node.</p> required <p>Returns:</p> Type Description <code>int</code> <p>The index of the layer the node belongs to.</p>"},{"location":"reference/bookacle/tree/structures/#bookacle.tree.structures.concatenate_node_texts","title":"concatenate_node_texts","text":"<pre><code>concatenate_node_texts(nodes)\n</code></pre> <p>Concatenate the texts of a list of nodes.</p>"}]}